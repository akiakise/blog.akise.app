[{"title":"利用 Cloudflare 重定向规则自动处理非法 URL","path":"//posts/cloudflare-redirect-invalid-url/","content":"在前文讲了如何使用 Cloudflare 重定向规则实现近似“无端口”访问带 IP 的服务（利用 Cloudflare 重定向规则摆脱端口访问服务）后，我们继续利用重定向规则来解决另一个常见的链接错误的问题。 问题当我们在社交&#x2F;论坛分享链接时，如果没有在链接后加上空格，那么链接后边的内容有很大的概率就会错误地被拼接上来，例如我们分享本文链接时结尾没加空格拼上了 ，测试test： 利用 Cloudflare 重定向规则自动处理非法 URLhttps://blog.akise.app/posts/cloudflare-redirect-invalid-url/，测试test 点击这个链接就会报 404 错误。 解决方案Hexo ❌Hexo 本身是一个静态博客，本站托管在 GitHub Pages 上，因此我们没有任何动态的手段来识别错误 URL 并进行处理。 Cloudflare ✔Cloudflare 支持针对请求的 URL 做重定向规则，看起来可以满足我们的诉求。那么首先我们明确下需要实现的功能：我们需要在博客链接包含错误字符时将其重定向到正常的链接。 假如错误的链接为：https://blog.akise.app/posts/cloudflare-redirect-invalid-url/，测试test 我们要将其重定向为：https://blog.akise.app/posts/cloudflare-redirect-invalid-url/ 在 Cloudflare 添加如下的重定向配置： 重定向配置 参数说明： 如果传入请求匹配…：自定义筛选表达式 URI 完整：通配符匹配 https://blog.akise.app/posts/*/*，精确匹配博客 URL 格式，其中第一个 * 匹配文档，第二个 * 匹配多余的字符 URI 路径：结尾不是 /，避免类似于 https://blog.akise.app/posts/cloudflare-redirect-invalid-url/ 的链接无限循环重定向 URL 重定向：动态重定向，表达式 wildcard_replace(http.request.uri.path, r&quot;/posts/*/*&quot;, r&quot;/posts/$&#123;1&#125;/&quot;)，状态代码 301 URL 匹配通过通配符和排除规则，针对如下 URL 会走到不同的处理逻辑： https://blog.akise.app/posts/cloudflare-redirect-invalid-url/: 由于结尾是 / 跳过 Cloudflare 处理 https://blog.akise.app/posts/cloudflare-redirect-invalid-url/，测试test: 匹配成功，需要重定向 https://blog.akise.app/posts/cloudflare-redirect-invalid-url: 由于缺少结尾的 / 跳过 Cloudflare 处理，Hexo 会自动在结尾加一个 / 重定向重定向规则使用 wildcard_replace，它会匹配第一个参数，并将其中的 * 编号替换到第二个参数中的 $&#123;数字&#125;，在 wildcard_replace(http.request.uri.path, r&quot;/posts/*/*&quot;, r&quot;/posts/$&#123;1&#125;/&quot;) 规则下针对如下入参： https://blog.akise.app/posts/cloudflare-redirect-invalid-url/，测试test 它会返回： https://blog.akise.app/posts/cloudflare-redirect-invalid-url/ 完美满足我们的诉求。 实验下面我们拼上其他字符进行试验： 拼上了“，测试”的URLhttps://blog.akise.app/posts/cloudflare-redirect-invalid-url/，测试 点击上述 URL 就不会再报 404 了，完美。 结语可以看到，Cloudflare 重定向规则还是很强大的，通过简单的配置就让我们对域名的访问流程有了较大的定制化能力，Cloudflare 还在测试一项名为 Snippets 的功能来直接通过 JavaScript 代码干涉访问流程，这样会更加简单便捷，不过目前仅限付费用户可用。 附言为了实现本文中部分 URL 访问 404、其他 URL 访问重定向的效果，我还在规则中另外增加了“URL 结尾不是 test”的规则 😊","tags":["Cloudflare"],"categories":["Technology"]},{"title":"Clash.Meta DNS 配置指南","path":"//posts/clash-dns-configure/","content":"随着互联网技术的发展与广告联盟的互联互通，大家对隐私的重视程度也越来越高，而 DNS 作为网络基础设施，其泄露的风险与泄露后导致的问题影响也越来越大。泄露可能涉及的问题主要有：用户通过虚拟专用网络或网络代理请求的域名被记录或审查、用户浏览历史被记录和分析用于广告投放或数据挖掘。同时 ISP 的 DNS 也天生自带污染和和劫持，并不推荐使用。 A DNS leak is a security flaw that allows DNS requests to be revealed to ISP DNS servers, despite the use of a VPN service to attempt to conceal them. Although primarily of concern to VPN users, it is also possible to prevent it for proxy and direct internet users. 虚空终端作为开源项目原神的二次开发版本，提供了更强的 DNS 处理能力，通过简单且合理的配置，可以尽最大可能规避 DNS 污染、劫持、泄露问题（不能做 100% 保证，毕竟不清楚还有没有未知的手段）。 DNS 解析流程下图来自虚空终端 wiki: DNS 解析流程 DNS Resolve 配置指南我们直接给出推荐配置，并结合上边的解析流程来详细分析： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147geodata-mode: true geodata-loader: memconservativegeo-auto-update: truegeo-update-interval: 24geox-url: geoip: &quot;https://testingcf.jsdelivr.net/gh/MetaCubeX/meta-rules-dat@release/geoip.dat&quot; geosite: &quot;https://testingcf.jsdelivr.net/gh/MetaCubeX/meta-rules-dat@release/geosite.dat&quot; mmdb: &quot;https://testingcf.jsdelivr.net/gh/MetaCubeX/meta-rules-dat@release/country.mmdb&quot; asn: &quot;https://github.com/xishang0128/geoip/releases/download/latest/GeoLite2-ASN.mmdb&quot;dns: enable: true prefer-h3: false # DOH 优先使用 http/3 use-hosts: true # 是否回应配置中的 hosts，默认 true use-system-hosts: false # 是否查询系统 hosts，默认 true，我们不用系统 hosts listen: 0.0.0.0:53 # DNS 服务监听，仅支持 udp ipv6: true # ipv6 解析开关 default-nameserver: # 默认 DNS, 用于解析 DNS 服务器 的域名，必须为 IP, 可为加密 DNS - 1.2.4.8 - tls://223.5.5.5 enhanced-mode: fake-ip # or reder-host fake-ip-range: 172.29.0.1/16 # Fake-IP 解析地址池 fake-ip-filter: # Fake-IP 过滤，列表中的域名返回真实 IP - &#x27;+.lan&#x27; - &#x27;+.in-addr.arpa&#x27; # 配置后面的nameserver、fallback和nameserver-policy向dns服务器的连接过程是否遵守遵守rules规则 # 如果为false（默认值）则这三部分的dns服务器在未特别指定的情况下会直连 # 如果为true，将会按照rules的规则匹配链接方式（走代理或直连），如果有特别指定则任然以指定值为准 # 仅当proxy-server-nameserver非空时可以开启此选项, 强烈不建议和prefer-h3一起使用 # 此外，这三者配置中的dns服务器如果出现域名会采用default-nameserver配置项解析，也请确保正确配置default-nameserver respect-rules: false # 配置查询域名使用的 DNS 服务器 nameserver-policy: &quot;+.lan,+.in-addr.arpa&quot;: system # 广告拦截，效果有限，请使用浏览器扩展等更有效的手段 &quot;geosite:category-ads-all&quot;: rcode://success # 禁止 apple 更新检测 &quot;geosite:apple-update&quot;: rcode://success &quot;rule-set:direct&quot;: # 阿里 DNS - tls://223.5.5.5 - tls://223.6.6.6 - &#x27;https://223.5.5.5/dns-query#h3=true&#x27; - &#x27;https://223.6.6.6/dns-query#h3=true&#x27; &quot;geosite:private,onedrive,microsoft@cn,apple@cn,steam@cn,google@cn,jetbrains@cn,category-games@cn,cn&quot;: # 阿里 DNS - tls://223.5.5.5 - tls://223.6.6.6 - &#x27;https://223.5.5.5/dns-query#h3=true&#x27; - &#x27;https://223.6.6.6/dns-query#h3=true&#x27; proxy-server-nameserver: - &#x27;https://223.5.5.5/dns-query#h3=true&#x27; - &#x27;https://223.6.6.6/dns-query#h3=true&#x27; nameserver: # Cloudflare - &#x27;tls://1.1.1.1#PROXY&#x27; - &#x27;tls://1.0.0.1#PROXY&#x27; - &#x27;https://1.1.1.1/dns-query#PROXY&amp;h3=true&#x27; - &#x27;https://1.0.0.1/dns-query#PROXY&amp;h3=true&#x27; # Google - &#x27;tls://8.8.8.8#PROXY&#x27; - &#x27;tls://8.8.4.4#PROXY&#x27; - &#x27;https://8.8.8.8/dns-query#PROXY&amp;h3=true&#x27; - &#x27;https://8.8.4.4/dns-query#PROXY&amp;h3=true&#x27; # 101 - &#x27;tls://101.101.101.101#PROXY&#x27; - &#x27;https://101.101.101.101/dns-query#PROXY&#x27; # dns.sb - &#x27;tls://185.222.222.222#PROXY&#x27; - &#x27;tls://45.11.45.11#PROXY&#x27; - &#x27;https://185.222.222.222/dns-query#PROXY&#x27; - &#x27;https://45.11.45.11/dns-query#PROXY&#x27;rule-providers: direct: behavior: classical type: inline payload: # CDN - &#x27;DOMAIN,download-cdn.jetbrains.com&#x27; # Clash Dashboard &amp; Converter - &#x27;DOMAIN,clash.razord.top&#x27; - &#x27;DOMAIN,yacd.haishan.me&#x27; - &#x27;DOMAIN,nexconvert.com&#x27; # DDNS - &#x27;DOMAIN-SUFFIX,ip.sb&#x27; # time - &#x27;DOMAIN,time.android.com&#x27; proxy: behavior: classical type: inline payload: # 这些域名虽然在国内有接入点，但是直连体验并不好，因此强制代理 - &#x27;DOMAIN,dockerstatic.com&#x27; - &#x27;DOMAIN,fonts.googleapis.com&#x27; - &#x27;DOMAIN,fonts.gstatic.com&#x27; - &#x27;DOMAIN,www.gstatic.com&#x27; reject: behavior: classical type: inline payload: # niconico 广告 - &#x27;DOMAIN-SUFFIX,ads.nicovideo.jp&#x27; # mumu 模拟器广告 - &#x27;DOMAIN-SUFFIX,mumu.nie.netease.com&#x27; # postman 更新 - &#x27;DOMAIN-SUFFIX,dl.pstmn.io&#x27; - &#x27;DOMAIN-SUFFIX,sync-v3.getpostman.com&#x27; - &#x27;DOMAIN-SUFFIX,getpostman.com&#x27;rules: # 个人规则，1.2.3.4 用作示例 - IP-CIDR,1.2.3.4/32,PROXY,no-resolve # 规则修正 - RULE-SET,reject,REJECT - RULE-SET,proxy,PROXY - RULE-SET,direct,DIRECT # 广告过滤 - GEOSITE,category-ads-all,REJECT # 强制直连 - GEOSITE,private,DIRECT - GEOSITE,onedrive,DIRECT # @cn 为该规则内的域名在中国大陆有接入点，可直连 - GEOSITE,microsoft@cn,DIRECT - GEOSITE,apple@cn,DIRECT - GEOSITE,steam@cn,DIRECT - GEOSITE,google@cn,DIRECT - GEOSITE,jetbrains@cn,DIRECT - GEOSITE,category-games@cn,DIRECT # 流媒体 - GEOSITE,biliintl,国际流媒体 - GEOSITE,youtube,国际流媒体 # 强制代理 - GEOSITE,google,PROXY - GEOSITE,twitter,PROXY - GEOSITE,pixiv,PROXY - GEOSITE,category-scholar-!cn,PROXY - GEOSITE,geolocation-!cn,PROXY # 兜底强制直连 - GEOSITE,cn,DIRECT # GEOIP 规则 - GEOIP,private,DIRECT - GEOIP,telegram,PROXY - GEOIP,JP,PROXY - GEOIP,CN,DIRECT # 兜底代理 - MATCH,PROXY 在这个配置中，最最核心的就是利用 GEOSITE 来进行域名规则的判断，以下我们分为几种情况来分析其解析流程。 1. 直接通过 ip 访问直接通过 1.2.3.4 访问会命中 IP-CIDR,1.2.3.4/32,PROXY,no-resolve 规则，它会跳过 DNS 解析流程并直接交给对应的策略处理（这里配置为 PROXY 策略）。 假设我们同时有一个域名 example.com 也指向了 1.2.3.4，那我们访问域名的时候并不会走到这条规则，因为规则添加了 no-resolve 条件，除非是直接通过 IP 访问，否则直接跳过此规则。 2. 访问境内域名，命中 GEOSITE 规则当访问的境内域名命中 GEOSITE 规则时，由于指定了 DIRECT 策略，虚空终端会进入 DNS 解析流程，结合配置文件来说流程如下： 查询 DNS 缓存，如果查到，拿出对应的 IP 并直接建立连接 匹配 nameserver-policy，我们将所有的境内规则的 GEOSITE 也都配置在了这里，因此肯定会命中这条规则。在 nameserver-policy 内容里我们配置了 AliDNS 的 DoT 和 DoH，虚空终端会并发查询这些 nameserver 并返回最快返回的结果 拿到域名解析结果，直接建立连接，并保存 DNS 缓存 3. 访问境外域名，命中 GEOSITE 规则当访问的境外域名命中 GEOSITE 规则时，由于指定了 PROXY 策略，因此虚空终端会直接将域名解析与请求处理路由到 PROXY 节点，跳过自身所有的 DNS 解析流程。 4. 访问任意域名，未命中境内或境外 GEOSITE 规则境内境外 GEOSITE 规则未命中时，规则解析一路往下走到 GEOIP 规则，GEOIP 规则判断前需要先拿到域名对应的 IP，因此虚空终端会发起一次 DNS 解析流程： 查询 DNS 缓存，如果查到，拿出对应的 IP 交给 GEOIP 规则判断 匹配 nameserver-policy，我们在这里配置的 GEOSITE 规则跟 rules 里用的 GEOSITE 规则是一致的，因此也无法命中 兜底使用 nameserver，在内容里我们配置了常用的境外 DoT 和 DoH，并且指定这些 DNS 查询时使用 PROXY 节点以加速（境外 DNS 境内直接访问延迟很高），同时配置了 proxy-server-nameserver 来避免鸡蛋问题（考虑到解析速度配置成了 AliDNS，无奈之举），另外节点如果支持 H3 则尽可能使用 H3（这点存疑，境内到境外 H3 稳定性不确定） 拿到域名解析结果，交给 GEOIP 规则判断，并保存 DNS 缓存 如果 GEOIP 规则判断直连，则直接建立连接，如果 GEOIP 规则未命中，则走到兜底使用代理建立连接 可以看到，我们兜底使用远程节点来解析未命中规则的域名，我个人倾向于假设未命中规则的都是境外域名，因此都由境外 DNS 解析来避免国内 DNS 保留记录。当然这里也可以改为使用境内 DNS 解析，两种策略任君自选。 5. 规则修正规则库不是万能的，因此必然会出现某些域名分流错误的情况，我们通过补充的 direct、proxy、reject 三个 RULE-SET 来前置修正规则。 补充说明: rule-providers我们将强制修正的规则通过 rule-providers 维护，这样做的好处是可以在 rules 和 dns 中使用 rule-set 引用同一份配置，无需重复编写。在配置内容上使用 inline + classical 配合的形式，使得我们无需依赖远程仓库（旧做法是使用 GitHub 仓库或者 gist 托管），同时又可以使用 DOMAIN-SUFFIX、DOMAIN-KEYWORD 等特性，调整成本非常低。 补充说明: default-nameserver、fallbackdefault-nameserver: 用于解析 nameserver、fallback、nameserver-policy 中通过域名指定的 DNS 服务器，我们使用 IP 配置 DoT 和 DoH 节点，因此不再需要此配置。fallback: 虚空终端之前 Clash 使用的策略，逻辑比较复杂，不再推荐，使用更加简单易懂的 nameserver-policy 替代。 补充说明: GEOIP + no-resolve 是错误用法网上存在很多在 GEOIP,CN,DIRECT 后加上 no-resolve 的，这实际上是一个错误的用法，GEOIP 类规则就是要解析出 IP 后再进行 IP 判定的，加了 no-resolve 后如果不是直接通过 IP 访问的话，这条规则就失效了。 同时，虚空终端的规则处理流程是从上往下严格有序的，如果遇到了 IP 类规则（GEOIP、IP-CIDR、IP-CIDR6 等）会尝试进行 DNS 解析拿到 IP 再判断这条规则，如果某个 IP 类规则不带 no-resolve 并且放的比较靠前，那么必然会产生多余的 DNS 解析。 因此，这里的正确用法是将所有的 IP 类规则（GEOIP、IP-CIDR、IP-CIDR6 等）统一放到域名规则之后，如配置中将所有的 GEOIP 规则都放到了最后边，同时针对需要直接指定 IP 访问的（配置示例中为 1.2.3.4）规则添加 no-resolve 来避免多余的 DNS 解析。 总结通过上述的配置与解析，相信你已经对虚空终端的处理流程了如指掌，如果配置过程中遇到什么问题或者与文章不符的情况欢迎评论。","tags":["Clash.Meta","Mihomo","DNS"],"categories":["Technology"]},{"title":"利用 Cloudflare 重定向规则摆脱端口访问服务","path":"//posts/cloudflare-redirect-rule/","content":"如果你拥有一个国内服务器或者你的宽带有公网 IP，那么你一定知道在当前环境下尝试通过 80&#x2F;443 提供服务有多困难。多数情况下我们只能另选其他端口，然而非 80&#x2F;443 端口在访问时必须准确写出端口，这在服务数量众多的情况下成本非常高。 本文通过借助 Cloudflare 的重定向规则来实现“无端口”访问非 80&#x2F;443 端口的服务，至少可以简化记忆端口的成本。 创建规则进入 Cloudflare 后台选中你的域名后转到规则页面: 创建规则 然后填充表单： 编辑规则 接下来，在 DNS 页面填入我们刚才在规则页面写的主机名，并打开Proxy status配置： DNS 配置 实际访问创建完成后稍等一段时间让 DNS 生效，我们再访问 https://d.akise.app 就会自动跳转到 http://192.168.10.20:9000，实现了“无端口”访问（其实就是把记录端口的事情交给 Cloudflare 来做了）: 实现效果 你还可以在填充表单时选中 Preserve query string 来让跳转后的链接保留 URL query string，以便无缝提供 API 服务，不过我并没有这样的需求，暂时没有验证过这块。","tags":["Cloudflare"],"categories":["Technology"]},{"title":"我在 NAS 上都部署了什么服务","path":"//posts/nas/","content":"前言我在 2022 年年中心血来潮买了一台群晖 DS220+，于是开启了折腾之旅，到现在也有两年半了，现在写这篇文章分享下我都在上边搭建了什么服务，供大家参考。 NAS 及配套设施 内存：DS220+ 默认的 2GB 内存自然是不够用的，加装一条 8GB 内存 硬盘：两块希捷 8TB 硬盘，不组建 NAT 使用（关键文件备份后边会讲到） UPS：APC BK650M2-CH 四插孔 UPS，可以单独给 NAS 供电 60 分钟，四插孔也方便把猫、路由器一起供上 内网穿透见 内网穿透详解 照片管理使用 Synology Photos 服务端配合 Photos Mobile 自动同步 iOS 上的照片到群晖，在服务端通过手动将照片移动到文件夹 -&gt; 创建基于文件夹的条件相册来使照片源文件井井有条，同时不失相册能力。 假设 2022 年 1 月去杭州旅游，则首先在 Synology Photos 中创建 出游/2022.1 杭州 文件夹并将相关照片都挪入此文件夹，然后创建基于该文件目录的条件相册。这样一方面我们可以在 Photos Mobile 上以相册形式看到照片，另一方面在真实的文件系统中这些文件也都组织在 出游/2022.1 杭州 文件夹下，备份起来也十分方便。 音乐管理使用 Navidrome 服务端配合 Amperfy（iOS），Navidrome 可以同步播放记录到 last.fm，Amperfy 支持 iOS 快捷指令，可以快速播放你喜爱的歌单。 不推荐音流，音流在 DDNS 情况下经常加载失败，一旦加载失败离线缓存歌单和在线歌单就完全割裂了，非常难受，Amperfy 没有这方面的问题。 影视动画管理因为我本人不看电视剧和电影，只看动画，所以这里只讲动画相关的方案。使用 ani-rss + qbittorrent + jellyfin 打造媒体库： ani-rss: 新一代追番工具，基于 mikanani.me 数据，从订阅到下载再到文件目录整理，一个 ani-rss 就足够了 qbittorrent：下载工具，打开做种并配合 PBH 使用 jellyfin：媒体库管理，ani-rss 会将下载目录组织为 emby&#x2F;jellyfin 更便于刮削的形式，我使用 jellyfin 配合 TMDB 插件刮削媒体库（注意，TMDB 需要配合代理使用）。 这样一旦有新番更新，ani-rss 就会自动通过 qbittorrent 下载并由 jellyfin 呈现，同时 jellyfin 也方便记录我们的追番进度。 重要文件备份重要文件我采取异盘、异地（公有云）备份，没有极端到冷热备份，这些备份我们通过群晖就可以搞定。 异盘备份前文硬盘部分我们两块硬盘没有组建 raid，一方面是为了有更大的空间挥霍，另一方面也是可以做异盘备份（虽然说同时买的硬盘大概率是同一批出厂，也有可能同时坏，不过毕竟是概率事件）。借助群晖的 Cloud Sync -&gt; WebDav 可以很方便的做异盘备份： Cloud Sync 如上图所示，我做了如下备份： 将 Obsidian 笔记从专用目录 /webdav-sync/Obsidian Vault 备份到了 /important/Obsidian Vault 将 OneDrive 文件从 /akiakise/OneDrive 备份到了 /important/OneDrive 将照片从 /photo 备份到了 /important/Photo 将 /important 备份到了 /important-backup，其中这两个目录分别处于两个硬盘上 如上，我们通过 Cloud Sync 收集需要备份的文件，并实现了重要文件的异盘备份。 需要注意的是，Cloud Sync 同步配置时需要将同步方向设置为「仅下载远程更改」，不然可能会有文件来回同步的问题。 异地备份在上边的本地备份时我们已经将文件都收集在 /important-backup 里了，接下来我们将其打包、加密、压缩后备份到公有云。 首先我们通过 Cloud Sync 将本地目录与公有云关联起来： Baidu Sync 这样百度网盘中 我的应用数据/Cloud Sync 目录就与本地的 /akiakise/BaiduNetDisk 建立了联系，两个目录之间的文件自动被 Cloud Sync 双向同步。 我们通过 Python 脚本完成本地文件的备份: 12345678910111213141516171819202122232425262728293031from datetime import datetime, timedeltaimport osdef now(): return f&quot;[&#123;datetime.now().strftime(&#x27;%Y-%m-%d %H:%M:%S&#x27;)&#125;]&quot;filename = datetime.today().strftime(&#x27;%Y%m%d&#x27;)expire_filename = (datetime.now() - timedelta(30)).strftime(&#x27;%Y%m%d&#x27;)password = &quot;YOURPASSWORD&quot;compress_dir = &quot;/volume2/important-backup&quot;target_dir = &quot;/volume1/akiakise/BaiduNetDisk/backup&quot;# directory checkos.makedirs(target_dir, exist_ok=True)# cleanup today backup files if existfor file in os.listdir(target_dir): if file.startswith(filename): file_path = os.path.join(target_dir, file) print(f&quot;&#123;now()&#125; exist today&#x27;s backup files, delete: &#123;file_path&#125;&quot;) os.remove(file_path)# compressres = os.system(f&quot;7z a -v2G -m0=Copy -mhe=on -p&#123;password&#125; &#123;target_dir&#125;/&#123;filename&#125;.7z &#123;compress_dir&#125;&quot;)if res != 0: print(f&quot;&#123;now()&#125; 7zip compress failed&quot;)# cleanup history filesfor file in os.listdir(target_dir): if file &lt; expire_filename: file_path = os.path.join(target_dir, file) print(f&quot;&#123;now()&#125; detected expire files, delete: &#123;file_path&#125;&quot;) os.remove(file_path)print(f&quot;&#123;now()&#125; done&quot;) 替换脚本中的 YOURPASSWORD 为你自己的密码，并替换 compress_dir 和 target_dir 里的目录即可，注意保留 /volume1 或 /volume2 前缀，它是群晖共享文件夹在文件系统中的真实路径。 这个脚本会将 compress_dir 中的文件打包、隐藏文件名、切分为 2GB 大小的分卷（不压缩，压缩太消耗 CPU 而且在照片场景效率不佳），然后移动到 target_dir 中，并删除 target_dir 中 30 天以前的备份文件（避免占用太大空间）。 如脚本所示，我们将文件备份到了 /akiakise/BaiduNetDisk/backup 目录下，它会被 Cloud Sync 自动上传到百度网盘 我的应用数据/Cloud Sync/backup 目录里，完美。 结语回头看，NAS 实打实的改变了我的生活，它无时无刻不在提升着我的幸福度，建议爱折腾的同学都入手一个。其实我的场景一个支持 Docker 的主机就能满足了，但是群晖系统的易用性也确实让我非常满意，后续升级硬件的话我还是会选择群晖。","tags":["NAS"],"categories":["Technology"]},{"title":"内网穿透详解","path":"//posts/nat-traversal/","content":"前言内网穿透的概念不再赘述，通常我们是希望能够在外出、旅行等不在家情况下也能访问家庭网络（例如查看 NAS 中的照片视频、远程连接内网设备进行办公等），而基于家庭网络环境，内网穿透又有几种不同的方案： 有公网 IPv4：DDNS 有公网 IPv6：DDNS 无公网 IP 有云服务器：FRP 无公网 IP 无云服务器：Tailscale、ZeroTier 等虚拟组网工具 本文以我的家庭网络环境为例，一篇文章讲明白这几种内网穿透的配置细节，读者可以结合自身的网络环境选取合适的方案。本文我们将所有的服务（Tailscale、FRP、DDNS）都放置在 NAS 上，以内网穿透访问 Windows 远程桌面作为目标： 目标 内网门锁多数内网穿透都是直接将内网服务穿透后暴露至公网，虽说内网服务也会有各自的密码，但是总会有未知的安全漏洞、我们也有可能误将无密码&#x2F;弱密码服务暴露出去，最好还是在内网服务前加一层 VPN。本文除 Tailscale 外的方案我们都采用 shadowsocks 作为内网服务的入口，预检所有流量，同时也实现流量的端到端加密： NAT Traversal with VPN 由于后续的 FRP、DDNS 方案都会用到 ss-server（多个方案可共用一个 ss-server），因此我们首先来创建下 ss-server。 1. 增加配置文件： $ $ 2. 编辑配置文件内容： 123456789&#123; &quot;server&quot;: &quot;::&quot;, &quot;server_port&quot;: 12300, &quot;password&quot;: &quot;lalala&quot;, &quot;timeout&quot;: 300, &quot;method&quot;: &quot;chacha20-ietf-poly1305&quot;, &quot;mode&quot;: &quot;tcp_and_udp&quot;, &quot;enable_udp&quot;: true&#125; 3. 使用 docker 管理服务： $ 4. 保险手段（每 30 分钟触发下 ss 启动，如果已启动则命令无效，避免手误将 ss 关掉后无法再连上）： $ 配置内容*&#x2F;30 * * * * docker start ss 上边我使用命令形式方便理解和减少截图，实际上在 NAS 中创建和管理容器是有图形化界面的，不过原理相同。 DDNS + IPv4有公网 IP 的情况下，通过 DDNS 实现内网穿透最为简单： DDNS+IPv4 ss-server 配置见文章开头「内网门锁」部分。 DDNS 脚本在 NAS 上新增 DDNS 脚本（也可以用已有的 DDNS 组件，原理是一样的）： 1234567891011121314151617181920#!/bin/shipv4=$(curl -sS ipv4.ip.sb)echo &#x27;[&#x27;`date +&quot;%Y-%m-%d %H:%M:%S&quot;`&#x27;]&#x27; &quot;current ipv4: $ipv4&quot;config_json=$(curl -sS -X GET &quot;https://api.cloudflare.com/client/v4/zones/&lt;ZONE_ID&gt;/dns_records/&lt;RECORD_ID&gt;&quot; -H &quot;X-Auth-Email: &lt;YOUR_EMAIL&gt;&quot; -H &quot;X-Auth-Key: &lt;YOUR_AUTH_KEY&gt;&quot; -H &quot;Content-Type: application/json&quot;)config_ipv4=$(echo $config_json | sed &#x27;s/.*content&quot;:&quot;\\(.*\\)&quot;,&quot;proxiable.*/\\1/g&#x27;)if [[ -z $config_ipv4 ]];then echo &#x27;[&#x27;`date +&quot;%Y-%m-%d %H:%M:%S&quot;`&#x27;]&#x27; &quot;current ipv4 is empty&quot; exit 1fiecho &#x27;[&#x27;`date +&quot;%Y-%m-%d %H:%M:%S&quot;`&#x27;]&#x27; &quot;config ipv4: $config_ipv4&quot;if [ &quot;$ipv4&quot; == &quot;$config_ipv4&quot; ]; then echo &#x27;[&#x27;`date +&quot;%Y-%m-%d %H:%M:%S&quot;`&#x27;]&#x27; &quot;current ipv4 and config ipv4 equals, skip&quot;else echo &#x27;[&#x27;`date +&quot;%Y-%m-%d %H:%M:%S&quot;`&#x27;]&#x27; $(curl -sS -X PUT &quot;https://api.cloudflare.com/client/v4/zones/&lt;ZONE_ID&gt;/dns_records/&lt;RECORD_ID&gt;&quot; \\ -H &quot;X-Auth-Email: &lt;YOUR_EMAIL&gt;&quot; \\ -H &quot;X-Auth-Key: &lt;YOUR_AUTH_KEY&gt;&quot; \\ -H &quot;Content-Type: application/json&quot; \\ -d &#x27;&#123;&quot;type&quot;:&quot;A&quot;,&quot;name&quot;:&quot;&lt;YOUR_DOMAIN_NAME&gt;&quot;,&quot;content&quot;:&quot;&#x27;$ipv4&#x27;&quot;,&quot;ttl&quot;:120, &quot;proxied&quot;:false&#125;&#x27;)\tfi 脚本中 &lt;&gt; 中的都是变量，需要替换下： ZONE_ID：在 Cloudflare 域名界面右下角的“区域ID” RECORD_ID：替换 ZONE_ID 后访问 https://dash.cloudflare.com/api/v4/zones/&lt;ZONE_ID&gt;/dns_records?per_page=200&amp;order=type&amp;direction=asc，找到 name 匹配你域名的记录的 id 字段 YOUR_EMAIL：你的 Cloudflare 账户邮箱 YOUR_AUTH_KEY：在 Cloudflare 域名界面右下角的“获取您的 API 令牌”，生成一个可以操作 DNS 的 API 令牌，使用“编辑区域 DNS”模板即可 YOUR_DOMAIN_NAME：你的 DDNS 要绑定的域名 注意，脚本会先比对当前数据是否一致，所以变量中 RECORD_ID 和 YOUR_DOMAIN_NAME 是一一对应的，即 RECORD_ID 应该就是 YOUR_DOMAIN_NAME 对应的 id。 端口转发在光猫&#x2F;路由器（桥接）上配置端口转发，将 12300 端口的流量转发至 NAS： DDNS Forward ss-client 配置客户端通过指定 IP 规则来实现用内网 IP 访问服务，以 Quantumult X 配置举例： 1234567[server_local]shadowsocks=ddns.domain.com:12300, method=chacha20-ietf-poly1305, password=lalala, fast-open=false, udp-relay=true, tag=ss[filter_local]# 我的内网网段为 192.168.10.x ip-cidr, 192.168.10.0/24, ssip-cidr, 192.168.0.0/16, direct 这样，客户端在访问 192.168.10.x 时 Quantumult X 就会将流量路由到 ss 节点，ss 节点看到域名后会去解析其对应的公网 IP，再然后 ss-client 会将流量加密后发往光猫&#x2F;路由器（桥接）的 12300 端口，光猫&#x2F;路由器（桥接）再依据端口转发规则将流量转发到 NAS 上的 ss-server，ss-server 解密流量后访问 192.168.10.x。 优缺点DDNS 方案的优点是不需要中转，流量直达家里的设备，能轻松跑到家宽上传上限，唯一的缺点是必须有公网 IP。 DDNS + IPv6受限于当前公网 IPv4 越来越难拿到，能给每一粒沙子都分配一个 IP 的 IPv6 成了另一个可行方案： DDNS+IPv6 依然是这张图，不过红线上的流量变成了 IPv6。 ss-server 配置见文章开头「内网门锁」部分。 DDNS 脚本在 NAS 上新增 DDNS 脚本（也可以用已有的 DDNS 组件，原理是一样的）： 12345678910111213141516171819ipv6=$(curl -sS ipv6.ip.sb)echo &#x27;[&#x27;`date +&quot;%Y-%m-%d %H:%M:%S&quot;`&#x27;]&#x27; &quot;current ipv6: $ipv6&quot;config_json_v6=$(curl -sS -X GET &quot;https://api.cloudflare.com/client/v4/zones/&lt;ZONE_ID&gt;/dns_records/&lt;RECORD_ID_V6&gt;&quot; -H &quot;X-Auth-Email: &lt;YOUR_EMAIL&gt;&quot; -H &quot;X-Auth-Key: &lt;YOUR_AUTH_KEY&gt;&quot; -H &quot;Content-Type: application/json&quot;)config_ipv6=$(echo $config_json_v6 | sed &#x27;s/.*content&quot;:&quot;\\(.*\\)&quot;,&quot;proxiable.*/\\1/g&#x27;)if [[ -z $config_ipv6 ]];then echo &#x27;[&#x27;`date +&quot;%Y-%m-%d %H:%M:%S&quot;`&#x27;]&#x27; &quot;current ipv6 is empty&quot; exit 1fiecho &#x27;[&#x27;`date +&quot;%Y-%m-%d %H:%M:%S&quot;`&#x27;]&#x27; &quot;config ipv6: $config_ipv6&quot;if [ &quot;$ipv6&quot; == &quot;$config_ipv6&quot; ]; then echo &#x27;[&#x27;`date +&quot;%Y-%m-%d %H:%M:%S&quot;`&#x27;]&#x27; &quot;current ipv6 and config ipv6 equals, skip&quot;else echo &#x27;[&#x27;`date +&quot;%Y-%m-%d %H:%M:%S&quot;`&#x27;]&#x27; $(curl -sS -X PUT &quot;https://api.cloudflare.com/client/v4/zones/&lt;ZONE_ID&gt;/dns_records/&lt;RECORD_ID_V6&gt;&quot; \\ -H &quot;X-Auth-Email: &lt;YOUR_EMAIL&gt;&quot; \\ -H &quot;X-Auth-Key: &lt;YOUR_AUTH_KEY&gt;&quot; \\ -H &quot;Content-Type: application/json&quot; \\ -d &#x27;&#123;&quot;type&quot;:&quot;AAAA&quot;,&quot;name&quot;:&quot;&lt;YOUR_DOMAIN_NAME_V6&gt;&quot;,&quot;content&quot;:&quot;&#x27;$ipv6&#x27;&quot;,&quot;ttl&quot;:120, &quot;proxied&quot;:false&#125;&#x27;)\tfi 脚本中 &lt;&gt; 中的都是变量，需要替换下： ZONE_ID：在 Cloudflare 域名界面右下角的“区域ID” RECORD_ID_V6：替换 ZONE_ID 后访问 https://dash.cloudflare.com/api/v4/zones/&lt;ZONE_ID&gt;/dns_records?per_page=200&amp;order=type&amp;direction=asc，找到 name 匹配你域名的记录的 id 字段 YOUR_EMAIL：你的 Cloudflare 账户邮箱 YOUR_AUTH_KEY：在 Cloudflare 域名界面右下角的“获取您的 API 令牌”，生成一个可以操作 DNS 的 API 令牌，使用“编辑区域 DNS”模板即可 YOUR_DOMAIN_NAME_V6：你的 DDNS 要绑定的域名 注意，脚本会先比对当前数据是否一致，所以变量中 RECORD_ID_V6 和 YOUR_DOMAIN_NAME_V6 是一一对应的，即 RECORD_ID_V6 应该就是 YOUR_DOMAIN_NAME_V6 对应的 id。 防火墙放行配置在 IPv6 情况下，端口转发已经没有必要了，因为所有内网设备分配的也都是公网 IP，我们需要做的是放行 ss-server 所在机器的防火墙。但是内网设备分配的公网 IP 也会动态变化，我们应该如何配置防火墙才能在 IP 变化时不需要调整配置呢？可以用 EUI-64 地址。 首先找到 ss-server 所在机器的 IPv6 地址，假设为 2001:2002:2003:2004:****:**ff:fe**:****，记下 ****:**ff:fe**:**** 部分，使用 EUI-64 &lt;需要暴露的主机的后缀&gt;/::ffff:ffff:ffff:ffff。 假设我们的 IPv6 地址为 2001:2002:2003:2004:1:20ff:fe25:2025，则对应 EUI-64 地址为 1:20ff:fe25:2025/::ffff:ffff:ffff:ffff，将这个地址填入防火墙放行即可： IPv6 Firewall Allow 注意：千万不要关闭 IPv6 防火墙，除非你明确知道这有什么后果！！！！！ 客户端配置客户端通过指定 IP 规则来实现用内网 IP 访问服务，以 Quantumult X 配置举例： 1234567[server_local]shadowsocks=ddnsv6.domain.com:12300, method=chacha20-ietf-poly1305, password=lalala, fast-open=false, udp-relay=true, tag=ss[filter_local]# 我的内网网段为 192.168.10.x ip-cidr, 192.168.10.0/24, ssip-cidr, 192.168.0.0/16, direct 这样，客户端在访问 192.168.10.x 时 Quantumult X 就会将流量路由到 ss 节点，ss 节点看到域名后会去解析其对应的公网 IP，再然后 ss-client 会将流量加密后发往光猫&#x2F;路由器（桥接）的 12300 端口，光猫&#x2F;路由器（桥接）再依据端口转发规则将流量转发到 NAS 上的 ss-server，ss-server 解密流量后访问 192.168.10.x。 注意，代理软件不能关闭 IPv6，否则域名解析不出来结果。 优缺点IPv6 方案的优点与 IPv4 相同，都是流量直达家里的设备，并且 IPv6 不需要额外向运营商申请。 FRP针对无公网 IP 有云服务器的情况，我们通过 FRP 来实现内网穿透： FRP ss-server 配置见文章开头「内网门锁」部分。 frps 配置假设中转服务器 IP 为 1.2.3.4，首先我们通过脚本安装 frp： 123wget https://raw.githubusercontent.com/mvscode/frps-onekey/master/install-frps.sh -O ./install-frps.shchmod +x ./install-frps.sh./install-frps.sh install 跟着提示安装即可，期间脚本会生成 frps 的 token，这个我们需要记录下。假设 frps 的端口为 12500，token 为 YOURFRPSTOKEN。 配置 systemd 管理 frps 服务： 1vim /etc/systemd/system/frps.service 填入以下内容： 123456789[Unit]Description=frps daemon[Service]Type=simpleExecStart=/usr/local/frps/frps -c /usr/local/frps/frps.toml[Install]WantedBy=multi-user.target 加载 systemd 服务并启动： 123systemctl daemon-reloadsystemctl start frpssystemctl enable frps 检查服务运行状态： 1systemctl status frps 现在 frps 会随着机器启动自动运行了。 frpc 配置新增配置文件： 12mkdir -p /docker/config/frpcvim /docker/config/frpc/frpc.toml 配置文件内容： 123456789101112131415serverAddr = &quot;1.2.3.4&quot;serverPort = 12500auth.token = &quot;YOURFRPSTOKEN&quot; # 替换为中转服务器的 token[[proxies]]name = &quot;shadowsocks&quot;type = &quot;tcp&quot;localPort = 12300remotePort = 12400[[proxies]]name = &quot;shadowsocks-udp&quot;type = &quot;udp&quot;localPort = 12300remotePort = 12400 使用 docker 方便管理服务： 1docker run --name frpc --restart=always --net host -v /docker/config/frpc/frpc.toml:/frp/frpc.toml -d stilleshan/frpc 这样，我们内网启动了 frpc，它会通过端口 12500 和 token YOURFRPSTOKEN 连接到公网中转服务器 1.2.3.4，告诉公网服务器监听 12400 端口的流量，并将发往这个端口的流量转发至 frpc 所在机器的 12300 端口。前文我们在 12300 端口部署了 shadowsocks，于是流量会经过 shaodowsocks 后进入内网。 客户端配置客户端通过指定 IP 规则来实现用内网 IP 访问服务，以 Quantumult X 配置举例： 1234567[server_local]shadowsocks=1.2.3.4:12400, method=chacha20-ietf-poly1305, password=lalala, fast-open=false, udp-relay=false, tag=ss[filter_local]# 我的内网网段为 192.168.10.x ip-cidr, 192.168.10.0/24, ssip-cidr, 192.168.0.0/16, direct 这样，客户端在访问 192.168.10.x 时 Quantumult X 就会将流量路由到 ss 节点，ss-client 将流量加密后发往 1.2.3.4 的 12400 端口，1.2.3.4 的 12400 端口实际是 FRP 映射的 NAS 的 12300 端口，于是流量就被发到内网 ss-server，ss-server 解密流量后访问 192.168.10.x。 优缺点FRP 方案的优点是不需要公网 IP，任何网络环境都可以部署，缺点是需要一台云服务器用于流量中转，同时该方案的网络带宽也受限于云服务器和家庭网络的上传上限，即 MAX(带宽) = MIN(云服务器上传, 家宽上传)。 TailscaleTailscale 的使用相较于其他方案非常简单，而且它不需要公网 IP 和云服务器，可谓是最低成本的内网穿透方案，但是由于 Tailscale 客户端会占用 VPN 通道（iOS），导致它无法与 Quantumult X 之类的共存，因此我只是将它作为一个备用的穿透工具。 注册在 https://tailscale.com/ 注册账号，并转到 https://login.tailscale.com/admin/settings/keys 来生成 auth key 和 access token: Tailscale Keys NAS 配置使用 docker 方便管理服务： 12mkdir /docker/config/tailscaledocker run --name tailscale --restart=always --net host --cap-add NET_ADMIN -v /docker/config/tailscale:/var/lib -v /docker/config/tailscale:/dev/net/tun -e TS_ROUTES=192.168.10.0/24 -e TS_AUTHKEY=刚申请的AuthKey -e TS_STATE_DIR=/var/lib/tailscale -d tailscale/tailscale 启动成功后即可在 Tailscale后台 看到机器上线了： Tailscale Machines 其中 Subnets 旁边的感叹号提示我们在 docker 启动时添加的网段还没有真实生效，接下来我们让它生效： Tailscale Subnet Config 1 Tailscale Subnet Config 2 这样，当其他设备加入 Tailscale 后就可以通过 192.168.10.x 访问 NAS 以及其他内网设备了。 客户端配置Tailscale 支持的平台相当广泛，客户端只需要登录账号即可完成配置，开启组网开关即可访问内网设备了。 狡兔三窟分布式系统中常说异地多活、容灾等概念，我们内网穿透也可以四种方案并存，以备不时之需，每种方案的配置细节与原理都写在上边了，任君组合 ~ 我的网络环境我所在的地区是可以下发动态公网 IP 的，所以我主要使用 DDNS + IPv4 的形式，不过我也配置了另外几种方案作为备份，以下是我的家庭网络拓扑： My NAT Traversal 总结本文我们介绍了内网穿透的几种方案，在各式各样工具的加持下，内网穿透现在已经不再是一个难题了。不过网络传输的稳定性依然是一个大问题，家宽上传更是万年的 30M，不过技术发展日新月异，这些问题迟早会被解决，期待那一天的到来！","tags":["NAS","DDNS","FRP","Tailscale"],"categories":["Technology"]},{"title":"Alfred 精确计算器","path":"//posts/alfred-accurate-calculator/","content":"背景Alfred 自带了一个计算器，可以在激活后直接输入运算符进行计算： Alfred calculator with big number 但是正如上图所示，Alfred 原生的计算器并不能处理大数场景，在公司内部开发时，我们经常需要跟 snowflake 算法生成的 ID 打交道（非常长的数字），因此就经常需要进行大数间的运算。 问题如上图的计算结果是：1.23456789e18，实际上等价于 1234567890000000000，是一个错误的结果。 我们期望的正确结果是：1234567890123456790，Alfred 原生计算器丢失了精度信息。 解决方案Python 在这种情况下工作正常： 12$ python3 -c &quot;print(eval(&#x27;1234567890123456789+1&#x27;))&quot;1234567890123456790 Python 做了很多努力来尽可能使它的数字类型（int）与数学层面上的数字等价，即从用户视角看，Python 的 int 并没有 Java 的 byte、char、int、long、bigint 的区分，是无限大的。 因此我们使用 Python 进行数字运算时，不需要考虑精度问题，这也为解决这个问题提供了一个方案。 实现如上一节的示例，我们只需要一个简单的 print(eval(&#39;$&#123;expression&#125;&#39;)) 即可，这里我将其封装为 Alfred 的 workflow，以便可以更简单的复用： https://github.com/akiakise/alfred-accurate-calculator/releases/tag/v1.0 下载 release 界面的 Accurate.Calculator.alfredworkflow 然后双击，Alfred 会自动完成安装进程。 使用呼出 Alfred 菜单后使用 calc 前缀激活 workflow，然后输入你的计算语句即可： Usage 1 Usage 2 Usage 3 源码https://github.com/akiakise/alfred-accurate-calculator","tags":["mac","alfred"],"categories":["Technology"]},{"title":"Spring 中的跨域问题","path":"//posts/spring-cross-origin/","content":"项目做前后端分离，遇到了一个很常见的问题：跨域。想着每次遇到都要搜索解决，而且搜到的文章给出的解决方案又千奇百怪，不一定合适，于是萌生了总结一下的想法。 问题由来跨站 HTTP 请求（Cross-site HTTP Request）是指发起请求的资源所在的 domain 与该请求所指向的 domain 不同的 HTTP 请求。比如，域名 abc(www.abc.com) 的某个标签引用了域名 cde(www.cde.com) 的某资源，域名 abc 的 Web 应用就会导致浏览器发起一个跨站 HTTP 请求。 这种方式极大地方便了 Web 开发，然而，出于安全考虑（主要是防范 csrf），浏览器会限制从脚本内发起的跨源 HTTP 请求。例如 XMLHttpRequest 和 Fetch API 遵循同源策略。这意味着使用这些 API 的 Web 应用程序只能从加载应用程序的同一个域请求 HTTP 资源。 然而如果我们在本地开发前后端分离程序，前端请求本机上的后端 API 却由于浏览器限制而请求失败，十分不便。 CORS跨域资源共享（CORS）机制允许 Web 应用服务器进行跨域访问控制，从而使跨域数据传输得以安全进行。现代浏览器支持在 API 容器中（例如 XMLHttpRequest 或 Fetch）使用 CORS，以降低跨域 HTTP 请求中所带来的风险。 功能概述跨域资源共享标准新增了一组 HTTP 首部字段，允许服务器声明哪些源站有权限通过浏览器访问哪些资源。另外，标准要求，对那些可能对服务器产生副作用的 HTTP 请求方法（特别是 GET 以外的 HTTP 请求，或者搭配某些 MIME 类型的 POST 请求），浏览器必须首先用 OPTIONS 方法发起一个预检请求（Preflight Request，请记住这个概念，后面会经常使用），从而获取服务器是否允许该跨域请求。服务器确认允许后，才发起实际的 HTTP 请求。在预检请求的返回中，服务器也可以通知客户端，是否携带身份凭证（包括 Cookie 和 HTTP 认证相关数据）。 CORS 请求失败会产生错误，但为了安全，在 JavaScript 代码层面是无法获知到底哪里出了问题。你只能查看浏览器控制台以得知具体是哪里出现了错误。 简单请求某些请求不会触发 CORS 预检请求。若请求满足所有下述条件，则请求可视为“简单请求”： 使用下列方法之一 GET HEAD POST 首部字段在 对 CORS 安全的首部字段集合 中： Accept Accept-Language Content-Language Content-Type（下一条为值限制） DPR Downlink Save-Data Viewport-Width Width Content-Type 的值为下列三者之一 text&#x2F;plain multipart&#x2F;form-data application&#x2F;x-www-form-urlencoded 请求中的任意 XMLHttpRequestUpload 对象均没有注册任何事件监听器 请求中没有使用 ReadableStream 对象 我们可以看到，简单请求的要求是十分严格的，这篇博客我们不会过多讨论简单请求。 预检请求与上一节的简单请求不同，预检请求要求必须首先使用 OPTIONS 方法发起一个预检请求到服务器，以获知服务器是否允许该实际请求。预检请求的使用，可以避免跨域请求对服务器的用户数据产生未预期的影响。 模拟跨域问题浏览器端使用 JavaScript 请求本地 API 即可： 12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Web&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div&gt; &lt;label for=&quot;name&quot;&gt;Name: &lt;/label&gt; &lt;input id=&quot;name&quot; type=&quot;text&quot; value=&quot;xlui&quot; autofocus/&gt; &lt;input type=&quot;button&quot; onclick=&quot;postData()&quot; value=&quot;Submit&quot;&gt; &lt;/div&gt; &lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;div&gt; Response:&lt;br&gt; &lt;textarea name=&quot;response&quot; id=&quot;response&quot; cols=&quot;30&quot; rows=&quot;5&quot;&gt;&lt;/textarea&gt; &lt;/div&gt; &lt;script&gt; function postData() &#123; var i = document.getElementById(&quot;name&quot;).value; var resp = document.getElementById(&quot;response&quot;); console.log(&#x27;try to submit &#x27; + i); var xhr = new XMLHttpRequest(); xhr.open(&#x27;post&#x27;, &#x27;http://127.0.0.1:8080/&#x27;, true) xhr.setRequestHeader(&#x27;content-type&#x27;, &#x27;application/json&#x27;) xhr.onreadystatechange = function() &#123; if (xhr.readyState === 4) &#123; console.log(xhr.responseText); resp.value = xhr.responseText; &#125; &#125; xhr.send(JSON.stringify(&#123; &#x27;username&#x27;: i &#125;)) &#125; &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 服务器端从简单做起，我们首先写一个简单的 Servlet 服务器： 123456789101112131415161718192021222324252627282930@WebServlet(name = &quot;MainServlet&quot;, urlPatterns = &quot;/&quot;)public class MainServlet extends HttpServlet &#123; protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; doGet(request, response); &#125; protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // 提取用户名 BufferedReader reader = new BufferedReader(new InputStreamReader(request.getInputStream())); String input; StringBuilder builder = new StringBuilder(); while ((input = reader.readLine()) != null) &#123; builder.append(input); &#125; input = builder.toString(); String username; try &#123; username = input.split(&quot;:&quot;)[1].replace(&quot;&#125;&quot;, &quot;&quot;).replace(&quot;\\&quot;&quot;, &quot;&quot;); &#125; catch (Exception e) &#123; username = &quot;defaultUsername&quot;; &#125; // 以上部分代码是为了从浏览器发送的数据中提取出 username 字段，不用认真阅读 User user = new User(username, &quot;pass&quot;); response.setContentType(&quot;application/json;charset=UTF-8&quot;); try (PrintWriter out = response.getWriter()) &#123; out.println(user); &#125; &#125;&#125; Servlet 中的跨域问题Servlet 中解决跨域问题很简单，利用 Filter 即可。根据上面的原理，在发送跨域请求之前，浏览器会首先以 OPTIONS 方法发送一个预检请求，如果允许跨域，则继续发送跨域请求，如果不允许，则阻止后续请求，并在 conole 打印错误。 我们定制 Filter： 12345678910111213141516171819202122232425@WebFilter(filterName = &quot;CorsFilter&quot;, urlPatterns = &quot;/*&quot;)public class CorsFilter implements Filter &#123; public void destroy() &#123; &#125; public void doFilter(ServletRequest req, ServletResponse resp, FilterChain chain) throws ServletException, IOException &#123; HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) resp; if (request.getMethod().equals(&quot;OPTIONS&quot;)) &#123; response.setHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;); response.setHeader(&quot;Access-Control-Allow-Methods&quot;, &quot;OPTIONS, GET, POST, PUT, DELETE&quot;); // -1 表示不缓存，正数值表示缓存预检请求的 秒 数 // 在预检请求缓存的有效期内，后续的跨域请求不需要再发送预检请求 response.setHeader(&quot;Access-Control-Max-Age&quot;, &quot;-1&quot;); response.setHeader(&quot;Access-Control-Allow-Headers&quot;, &quot;Authorization,x-requested-with,content-type&quot;); response.setHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;); return; &#125; response.setHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;); chain.doFilter(req, resp); &#125; public void init(FilterConfig config) throws ServletException &#123; &#125;&#125; 对 OPTIONS 的处理上：因为这个请求只是为了检查服务器是否支持跨域，所以我们在设置完相应的 Header 之后可以直接 return，即不需要进行后续处理。 对其他 HTTP 方法，必须附带 Access-Control-Allow-Origin，否则虽然请求能够成功完成，浏览器会阻止结果的显示。可以注释掉 chain.doFilter 上一行的设置 Header 语句重新运行，在浏览器控制台的 Network 中可以看到请求返回的数据，但是不会显示在网页，并且控制台也会正常报错。说明浏览器阻止了 XMLHttpRequest 结果的显示。 Spring Mvc 中的跨域问题解决起来跟上面的类似，还是利用 Filter，不过鉴于这个问题的常见，Spring 为我们提供了一个实现好的 CorsFilter：org.springframework.web.filter.CorsFilter，我们只需要提供必要的参数，然后使用这个 Filter 即可。 示例代码我使用 Spring Boot + Spring Mvc，下面是 Controller： 1234567@RestControllerpublic class WebController &#123; @RequestMapping(value = &quot;/&quot;, method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_UTF8_VALUE) public User index(@RequestBody @NotNull User user) &#123; return new User(user.getUsername(), &quot;spring-mvc-pass&quot;); &#125;&#125; 如果不加其他措施我们是不能通过跨域访问 http://127.0.0.1:8080/ 的，下面我们将 Spring 提供的 Filter 加入示例项目： 123456789101112131415@Configurationpublic class CorsConfig &#123; @Bean public CorsFilter corsFilter() &#123; final CorsConfiguration configuration = new CorsConfiguration(); configuration.setAllowedOrigins(List.of(&quot;*&quot;)); configuration.setAllowedMethods(List.of(&quot;OPTIONS&quot;, &quot;POST&quot;, &quot;GET&quot;)); configuration.setAllowedHeaders(List.of(&quot;*&quot;)); configuration.setMaxAge(-1L); configuration.setAllowCredentials(true); final UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(&quot;/**&quot;, configuration); return new CorsFilter(source); &#125;&#125; 重新运行项目，已经可以成功从浏览器端发送跨域请求并接收响应了。 简单查看 CorsFilter 的源码，实现思想与我们自己实现的大体相同。具体来说是：首先通过 AntPathMatcher 获取到我们用 source.registerCorsConfiguration 注册的配置，然后进行预处理： 如果请求不是 Cors 请求（请求头包含 Origin 字段），则跳过 CorsFilter 如果有其他 Filter 已经在请求头中添加了 Access-Control-Allow-Origin 字段，跳过 CorsFilter 如果是同源请求，跳过 CorsFilter 如果配置为空，并且该请求是预检请求（Preflight Request，请求头有 Origin 字段、请求是 OPTIONS 方法，请求头不包含 Access-Control-Allow-Origin 字段），则拒绝该请求 如果配置为空，并且该请求不是预检请求，则跳过 CorsFilter 预处理之后进行跨域权限检查： 检查 Origin 是否符合配置，不符合则拒绝请求 检查请求 Method 是否符合配置，不符合则拒绝请求 检查 Headers 是否符合配置，不符合则拒绝请求 然后设置响应： setAccessControlAllowOrigin setAccessControlAllowMethods（仅预检请求） setAccessControlAllowHeaders（仅预检请求，并且配置了 Allowed Headers） setAccessControlExposeHeaders（配置了 Expose Headers） setAccessControlAllowCredentials（配置了 Allowed Credentials） setAccessControlMaxAge（仅预检请求，并且配置了 Max Age） 可以看出来，比起我们自己设计 CorsFilter，Spring 提供的 CorsFilter 还自己根据配置进行了各种检查，而我们在使用的时候只需要传入自定义的配置即可，极大地简化了开发难度同时又增加了灵活性。 Spring 4.2 以后的跨域问题Spring Framework 4.2 版本开始原生支持跨域，相较于之前配置 Filter 的方式，Spring 提供了一个注解 @CorssOrigin 来简化配置。 我们只需要将 @CrossOrigin 添加在需要的 API 或者 Controller 上，然后设置其参数即可完成配置： 1234567891011@CrossOrigin( origins = &quot;*&quot;, methods = &#123;RequestMethod.OPTIONS, RequestMethod.GET, RequestMethod.POST&#125;, allowedHeaders = &#123;&quot;Authorization&quot;, &quot;Content-Type&quot;&#125;, maxAge = -1L, allowCredentials = &quot;false&quot;)@RequestMapping(value = &quot;/&quot;, method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_UTF8_VALUE)public User index(@RequestBody @NotNull User user) &#123; return new User(user.getUsername(), &quot;spring-mvc-pass&quot;);&#125; 或者直接使用默认配置 12345@CrossOrigin@RequestMapping(value = &quot;/&quot;, method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_UTF8_VALUE)public User index(@RequestBody @NotNull User user) &#123; return new User(user.getUsername(), &quot;spring-mvc-pass&quot;);&#125; 我们还可以通过 Configuration 来手动配置全局规则： 123456789@Configurationpublic class WebMvcConfig implements WebMvcConfigurer &#123; @Override public void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping(&quot;/conf&quot;) .allowedOrigins(&quot;*&quot;) .allowedMethods(&quot;OPTIONS&quot;, &quot;GET&quot;, &quot;POST&quot;); &#125;&#125; 1234@RequestMapping(value = &quot;/conf&quot;, method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_UTF8_VALUE)public User config(@RequestBody @NotNull User user) &#123; return new User(user.getUsername(), &quot;spring-mvc-pass&quot;);&#125; 参考链接 HTTP 访问控制（CORS）","tags":["java","spring","cross region"],"categories":["Java"]},{"title":"Maven 中的 Scope","path":"//posts/maven-scope/","content":"Maven 中 scope 的取值一共有 compile、test、runtime、provided、system 这几种，其实没有必要专门写一篇博客来讲。但是最近遇到了一个相关的坑，其实也不能说是坑，主要原因是自己对这些东西一知半解，所以还是有必要深究一下。 compilecompile 是默认的 scope，即不显式声明条件下 scope 就是 compile。compile 表示该依赖需要参与项目编译、测试、运行等所有步骤中，是最强的依赖，打包时通常需要包含进去。 testtest 表示依赖项目仅仅参与测试相关的工作，包含测试代码的编译、执行，但是原项目的编译、运行均不参与其中。 runtimeruntime 表示依赖不会参与项目的编译，不过会参与到后续的测试与运行环节中。与 compile 相比只是少了编译阶段，那为什么要提供这个 scope 呢？ StackOverflow 上有一个经典回答：https://stackoverflow.com/a/12273576/7944150。简单翻译下，声明 scope 为 runtime 的依赖通常是需要动态加载的代码，比如 JDBC 驱动，或者其他运行时通过 Java 反射调用加载的类。将这种依赖设置为 runtime 可以避免代码中意外的依赖，同时避免依赖传递。 注意，原回答中关于传递依赖的说法是错误的，参考 Dependency Mechanism，本文下方也会给出这个传递依赖表。 providedprovided 表明打包时可以不将依赖打包进去，JDK 或者容器会提供该依赖，典型的就是 servlet-api.jar，Tomcat 容器或者其他容器一般会提供这个 jar，所以我们就不需要将其声明为 compile。后一种做法还可能导致依赖冲突。 systemsystem 表明该依赖存在于本地系统，需要提供 JAR 路径，比较少用。 依赖传递存在 A -&gt; B -&gt; C，项目 A 依赖于项目 B，B 又依赖于 C。当知道 B 在 A 中的 scope 时，如何确定 C 的 scope？ C 在 B 中 scope 为 test 或 provided 时，C 直接丢弃，A 不依赖于 C 否则 A 依赖于 C，C 在 A 中的 scope 由 C 在 B 中的 scope 决定 B在A中的scope \\ C在B中的scope compile provided runtime test compile compile - runtime - provided provided provided provided - runtime runtime - runtime - test test - test - 表格中交叉部分的单元格即为 C 在 A 中的 scope，单元格取值为 “-” 则代表 C 不能被 A 传递依赖。 遇到的问题我最近在学 Netty，编解码部分用到了 JBoss Marshalling，这个编解码框架有一个通用的 API 以及有几个不同的实现： 通用 API 为：org.jboss.marshalling &gt;&gt; jboss-marshalling，可选的实现有： org.jboss.marshalling &gt;&gt; jboss-marshalling-river org.jboss.marshalling &gt;&gt; jboss-marshalling-osgi org.jboss.marshalling &gt;&gt; jboss-marshalling-serial 我的项目用到了 serial 版本的实现，但是在添加依赖的时候失误将其 scope 设置成了 test，造成一直无法成功编码、解码。定位问题的方法是将编码解码方法单独摘出来调用，发现这一行返回了 null： 1final MarshallerFactory factory = Marshalling.getProvidedMarshallerFactory(&quot;serial&quot;); 于是想到 serial 的依赖可能没有成功导入…. 在将其依赖重设为 compile 之后项目成功跑起来了。在补充了 scope 相关的知识后我认为 serial 正确的 scope 应该是 runtime，因为这个依赖存在的目的就是通过反射被加载，编译期是不需要的。修改 scope 之后果然不出所料。 所以 runtime 存在的意义就是将抽象与实现解耦，我们可以以 compile 依赖一个 API，然后通过 runtime 依赖其多种不同的实现，根据需要进行使用。 以上为个人理解，如有不符之处，欢迎指出 :-) 引申综合考虑以上几种 scope 的特性，当我们想在 Spring Boot 项目中全局排除某一个依赖时，应该如何处理？ 查看答案答案是在依赖声明时将其直接声明为 provided，由于 provided 代表着由 JDK 或者容器提供该依赖，而 Spring Boot 项目本身不需要容器即可运行（或者说它本身已经带了一个容器），所以将依赖设为 provided 可以确保该依赖不会被编译也不会被打包进最终的 jar&#x2F;war，从而实现全局排除的效果。","tags":["java","maven"],"categories":["Technology"]},{"title":"聊聊延时任务队列","path":"//posts/delayed-task-queue/","content":"延时队列，顾名思义，是为了让一些任务不立即执行，放到队列里面等到特定时间后再执行。常用的场景有： 订单一直处于未支付状态，需要及时关闭订单，并退还库存 用户通过遥控设备控制智能设备在指定时间进行工作 eFuture 中未来邮件需要在用户指定的时间点发送 eFuture 是我最近刚完成的一个项目，主要目的是提供“未来邮件”的服务。其中，邮件需要被存储并且需要在特定时间点发送。于是我就需要一个延时队列来保存发信任务，并在指定时间由程序消费任务，从而发送邮件。 对于 eFuture 来说，有两件事是最重要的： 未来邮件在延时任务队列中保存，并且不会因为系统故障（如突发停机）而丢失 未来邮件需要在指定日期被取出并消费掉（发送出） 这两点需求意味着，提供延时任务的组件需要具备容灾能力，所以常用的 Java 内部的实现就不行了（虽说我也没用 Java 来写这个项目）。一番搜索之后，发现常用的实现有两个符合我的要求：RabbitMQ 与 Redis。 RabbitMQRabbitMQ 本身并没有直接支持延时队列功能，但是我们可以通过 RabbitMQ 队列的特性模拟出延时队列的功能。 RabbitMQ 在创建 Queue 的时候可以指定一个 x-dead-letter-exchange 的选项，指定该选项后， Queue 中过期的消息都将自动转发到相应的 Exchange。我们只需要在对应的 Exchange 上绑定接收过期任务的队列即可。 Python 代码： 1234567891011121314151617181920212223242526import loggingimport threadingimport pikaconnection = pika.BlockingConnection(pika.ConnectionParameters( host=&#x27;localhost&#x27;, port=5672, virtual_host=&#x27;/&#x27;, credentials=pika.PlainCredentials(&#x27;user&#x27;, &#x27;user&#x27;)))channel = connection.channel()logging.basicConfig( level=logging.INFO, format=&#x27;%(asctime)s [%(levelname)s] %(message)s&#x27;, datefmt=&#x27;%H:%M:%S&#x27;)channel.exchange_delete(&#x27;msg.exchange&#x27;)channel.queue_delete(&#x27;msg.queue.dead&#x27;)channel.queue_delete(&#x27;msg.queue.task&#x27;)channel.exchange_declare(&#x27;msg.exchange&#x27;)channel.queue_declare(&#x27;msg.queue.dead&#x27;, arguments=&#123;&#x27;x-dead-letter-exchange&#x27;: &#x27;msg.exchange&#x27;&#125;)channel.queue_declare(&#x27;msg.queue.task&#x27;)channel.queue_bind(queue=&#x27;msg.queue.task&#x27;, exchange=&#x27;msg.exchange&#x27;, routing_key=&#x27;msg.queue.dead&#x27;) 上面这段代码主要做了： 利用 pika 连接到 RabbitMQ 配置 logging 清除已有的同名 Exchange 与 Queue 创建 Exchange 与 Queue 并对其中一个队列设置 dead-letter-exchange。 下面开始测试： 1234567891011121314151617181920212223def push(): for i in range(1, 6): logging.info(&#x27;push &#123;&#125;&#x27;.format(i)) channel.publish( exchange=&#x27;&#x27;, routing_key=&#x27;msg.queue.dead&#x27;, body=&quot;hello, &#123;&#125;&quot;.format(i), properties=pika.spec.BasicProperties(content_type=&quot;text/plain&quot;, expiration=str(1000 * i)) )def pop(): for method, properties, body in channel.consume(&#x27;msg.queue.task&#x27;): logging.info(&#x27;receive &#123;&#125;&#x27;.format(body))if __name__ == &#x27;__main__&#x27;: tPush = threading.Thread(target=push) tPop = threading.Thread(target=pop) logging.info(&#x27;start push...&#x27;) tPush.start() logging.info(&#x27;start pop...&#x27;) tPop.start() push 依次向 RabbitMQ 的 msg.queue.dead 中发布了 hello, 1, hello, 2, hello, 3, hello, 4, hello, 5，其中 hello, i 的过期时间为 i 秒。 pop 监听 RabbitMQ 的 msg.queue.task，一旦其中有数据就将其取出进行消费。 运行一下： 12345678910111215:00:50 [INFO] start push...15:00:50 [INFO] push 115:00:50 [INFO] start pop...15:00:50 [INFO] push 215:00:50 [INFO] push 315:00:50 [INFO] push 415:00:50 [INFO] push 515:00:51 [INFO] receive b&#x27;hello, 1&#x27;15:00:52 [INFO] receive b&#x27;hello, 2&#x27;15:00:53 [INFO] receive b&#x27;hello, 3&#x27;15:00:54 [INFO] receive b&#x27;hello, 4&#x27;15:00:55 [INFO] receive b&#x27;hello, 5&#x27; 看起来我们似乎成功实现了延迟任务队列，在上面的测试用例下这个队列也工作的很好。但是，上面的实现中却有一个致命缺陷，我们把 push 函数稍稍修改一下： 12345678910def push(): # for i in range(1, 6): for i in range(5, 0, -1): logging.info(&#x27;push &#123;&#125;&#x27;.format(i)) channel.publish( exchange=&#x27;&#x27;, routing_key=&#x27;msg.queue.dead&#x27;, body=&quot;hello, &#123;&#125;&quot;.format(i), properties=pika.spec.BasicProperties(content_type=&quot;text/plain&quot;, expiration=str(1000 * i)) ) 再次运行： 12345678910111215:02:47 [INFO] start push...15:02:47 [INFO] push 515:02:47 [INFO] start pop...15:02:47 [INFO] push 415:02:47 [INFO] push 315:02:47 [INFO] push 215:02:47 [INFO] push 115:02:52 [INFO] receive b&#x27;hello, 5&#x27;15:02:52 [INFO] receive b&#x27;hello, 4&#x27;15:02:52 [INFO] receive b&#x27;hello, 3&#x27;15:02:52 [INFO] receive b&#x27;hello, 2&#x27;15:02:52 [INFO] receive b&#x27;hello, 1&#x27; 可以看到，我们只是把插入消息的顺序调整了一下，队列就失去了作用。在新的 push 函数中，我们把过期时间长的任务先插入队列 msg.queue.dead，可以看到，只有在第一个消息过期并被转发到 msg.queue.task 后，后面的过期的消息才会被处理。 换言之，如果在 msg.queue.dead 中存在先后两个 task，第一个 task 过期时间 10s，第二个过期时间 1s，两个 task 是同时插入队列的。那么只有等第一个 task 过期从队列里移出后，第二个 task 才会被处理，尽管它在第一个 task 过期前就已经过期了。从中我们也可以看出 RabbitMQ 对于声明了 x-dead-letter-exchange 的队列中过期消息的处理策略：只检测最前面一个消息是否过期，如果过期就转发到指定的 Exchange，如果没有过期就不作任何处理。 RabbitMQ 的这种特性显然与我们的需求是相悖的，我们需要的是队列头元素始终是最接近过期的，所以我又将目光转向了 Redis。 RedisRedis 内部也没有对延时队列做支持，我们需要使用 Redis 的 zset 来手动实现。ZSet 是 Redis 内置的数据结构之一，其特性是值依据对应的 score 排序，内部使用 HashMap 与 SkipList 来存储数据并保证有序，HashMap 中存放的是值到 score 的映射，SkipList 中存放的是所有值，排序依据是 score。 利用 Redis 实现延时队列主要是就利用 ZSet，将值设置为 task，而 score 设置为任务执行时间点的 timestamp。然后 通过比较当前时间戳与 zset 中第一个元素的 score 来判断其是否过期。 Python 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445import loggingimport datetimeimport redisQUEUE_KEY = &#x27;delayed task queue&#x27;pool = redis.ConnectionPool(host=&#x27;localhost&#x27;, port=6379, db=0, password=&#x27;&#x27;)connection = redis.Redis(connection_pool=pool)logging.basicConfig( level=logging.INFO, format=&#x27;%(asctime)s [%(levelname)s] %(message)s&#x27;, datefmt=&#x27;%H:%M:%S&#x27;)def push(message: str, date: datetime.datetime): connection.zadd(QUEUE_KEY, message, date.timestamp())def pop(): task = connection.zrange(QUEUE_KEY, 0, 0) if not task: return False, &#x27;&#x27; message = task[0] timestamp = connection.zscore(QUEUE_KEY, message) now = datetime.datetime.now().timestamp() if timestamp &lt; now or abs(timestamp - now) &lt;= 1e-6: connection.zrem(QUEUE_KEY, message) return True, message return False, &#x27;&#x27;if __name__ == &#x27;__main__&#x27;: now = datetime.datetime.now() logging.info(&#x27;push hello 1&#x27;) # 3 秒后过期 push(&#x27;hello 1&#x27;, now + datetime.timedelta(seconds=3)) logging.info(&#x27;push hello 2&#x27;) # 7 秒后过期 push(&#x27;hello 2&#x27;, now + datetime.timedelta(seconds=7)) while True: boolean, message = pop() if boolean: logging.info(message) 代码意思应该很明了，我们运行上述代码： 123415:30:17 [INFO] push hello 115:30:17 [INFO] push hello 215:30:20 [INFO] b&#x27;hello 1&#x27;15:30:24 [INFO] b&#x27;hello 2&#x27; 修改两个 task 的过期时间： 1234567now = datetime.datetime.now()logging.info(&#x27;push hello 1&#x27;)# 7 秒后过期push(&#x27;hello 1&#x27;, now + datetime.timedelta(seconds=7))logging.info(&#x27;push hello 2&#x27;)# 3 秒后过期push(&#x27;hello 2&#x27;, now + datetime.timedelta(seconds=3)) 然后再次运行： 123415:33:12 [INFO] push hello 115:33:12 [INFO] push hello 215:33:15 [INFO] b&#x27;hello 2&#x27;15:33:19 [INFO] b&#x27;hello 1&#x27; 可以看到，如我们预期正确的执行了。 在代码中 while True 无限循环尝试取出元素是对 CPU 资源的一种浪费，同时也给 Redis 产生了不小的压力，我们可以放缓速度，比如每秒检测一次： 123while True: time.sleep(1) boolean, message = pop() 总结除了文中提到的两种实现方式，延时队列还可以使用数据库定期轮询、DelayQueue、Timer、时间轮、Quartz 等方式实现，本文中没有讨论这些，等将来碰到相关使用场景后，或许会填这个坑 :) 使用 Redis 作为延时任务队列的实现，在具体应用的时候我们需要开启 Redis 的持久化，最好两种方式同时开启，同时定期备份 Redis 持久化文件，最大程度避免任务丢失。","tags":["queue","redis","rabbitmq"],"categories":["Technology"]},{"title":"利用 Travis CI 自动测试、部署 Java Web 项目到 Tomcat","path":"//posts/travis-tomcat/","content":"上一个项目的部署测试流程是：本地写完，本地测试，打包为 war 上传到服务器，服务器部署到 Tomcat 指定目录下，重启 Tomcat。这一套流程下来少说十分钟，而且如果刚上传完发现有 bug 的话，还要本地改完重新再来一遍。 重复这样的过程让人心神俱疲，好在现在已经有成熟的解决方案如 Travis CI、Jenkins等，今天我们就尝试着在 Java Web 项目中运用 Travis CI 来自动测试、部署、重启。 Travis CI 是软件开发领域一个在线的、分布式的持续集成服务，它与 GitHub 的协作相当紧密，并且对开源项目免费。 注册配置 Travis到 Travis 的官网 https://travis-ci.org 注册登录，其实是用 GitHub 做第三方授权登录，十分简单。 注册成功后进入个人 Profile 页，选择一个需要集成 Travis CI 的项目，开启 Build 即可。 创建项目本文我们以一个简单的 Spring Boot 项目为例： 项目目录树12345678910111213141516171819202122232425262728293031323334353637383940414243│ .gitignore│ .travis.yml│ LICENSE│ README.md│└─Hello │ .gitignore │ HelloTravisCI.iml │ mvnw │ mvnw.cmd │ pom.xml │ ├─.idea │ └─.... │ ├─.mvn │ └─wrapper │ maven-wrapper.jar │ maven-wrapper.properties │ ├─src │ ├─main │ │ ├─java │ │ │ └─me │ │ │ └─xlui │ │ │ └─spring │ │ │ Application.java │ │ │ HelloController.java │ │ │ │ │ └─resources │ │ │ application.properties │ │ │ │ │ ├─static │ │ └─templates │ └─test │ └─java │ └─me │ └─xlui │ └─spring │ ApplicationTests.java │ └─target └─.... HelloController12345678910111213141516package me.xlui.spring;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class HelloController &#123; @RequestMapping(value = &quot;/&quot;, method = RequestMethod.GET) public String index() &#123; return &quot;&lt;html&gt;&quot; + &quot;&lt;head&gt;&lt;title&gt;Test Page&lt;/title&gt;&lt;/head&gt;&quot; + &quot;&lt;body&gt;&lt;div align=\\&quot;center\\&quot;&gt;Hello World!&lt;/div&gt;&lt;br&gt;&lt;br&gt;&lt;div align=\\&quot;center\\&quot;&gt;This website shows you have successfully integrated &lt;b&gt;Travis-CI&lt;/b&gt;&lt;/div&gt;&quot; + &quot;&lt;/body&gt;&lt;/html&gt;&quot;; &#125;&#125; 测试1234567891011121314151617package me.xlui.spring;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;@RunWith(SpringRunner.class)@SpringBootTestpublic class ApplicationTests &#123; @Test public void contextLoads() &#123; System.out.println(&quot;This is a simple test, and you pass it.&quot;); &#125;&#125; 添加 .travis.ymlTravis 需要根据项目中 .travis.yml 文件中的配置信息来执行相应的动作。 12345language: javajdk: - openjdk8install: cd Hello &amp;&amp; mvn install -DskipTests=true -Dmaven.javadoc.skip=truescript: mvn test 注意 install 的一行，根据目录树，我们的项目是在 Hello 目录下的，所以 install 的时候需要先切换到 Hello 目录中，否则 Maven 会找不到 pom.xml 进而构建失败。 触发构建提交并 push 到 GitHub 后，Travis就会自动构建这个 Maven 工程，可以在 Travis 上看到构建结果和过程中的详细输出： 自动部署现在 Travis 已经可以根据我们的提交自动执行构建过程了，下一步就是部署到远程服务器。 Travis 提供 after_success 来实现这个步骤。 不过在此之前有一件事需要处理，因为我们要部署到服务器，势必需要 Travis 登录远程服务器，因为是开源项目，我们应该怎么解决登录密码问题？ 加密登录密码Travis Docs 提供了这个问题的解决方案，我们一起来实践一下： 以下操作完全是在本地！！！ 首先通过 ruby 的 gem 安装 travis： 12345678# 安装 rubysudo yum install ruby ruby-devel# 更新 gemsudo gem update --system# 添加 ruby-china 源sudo gem sources --add https://gems.ruby-china.org/# 安装 travissudo gem install travis 接下来在命令行登录 travis： 1234567891011$ travis loginWe need your GitHub login to identify you.This information will not be sent to Travis CI, only to api.github.com.The password will not be displayed.Try running with --github-token or --auto if you don&#x27;t want to enter your password anyway.Username: xluiPassword for xlui: *********************Two-factor authentication code for xlui: ******Successfully logged in as xlui! 输入 GitHub 用户名、密码、两步认证码（如果开启了的话）。 将目录切换到项目根目录，因为我们要让 travis 远程登录自己的服务器，所以需要将本地保存的 SSH 私钥进行加密处理。（默认大家都是通过 ssh 登录服务器） 12345678910$ cd test-travis-ci/$ travis encrypt-file ~/.ssh/id_rsa --addDetected repository as xlui/test-travis-ci, is this correct? |yes| yesencrypting ~/.ssh/id_rsa for xlui/test-travis-cistoring result as id_rsa.encstoring secure env variables for decryptionMake sure to add id_rsa.enc to the git repository.Make sure not to add ~/.ssh/id_rsa to the git repository.Commit all changes to your .travis.yml. 这个时候查看 .travis.yml 会发现多出了几行： 123before_install: - openssl aes-256-cbc -K $encrypted_9655a05d2431_key -iv $encrypted_9655a05d2431_iv -in id_rsa.enc -out ~\\/.ssh/id_rsa -d 为了保证权限正常，我们多加一行设置： 1234before_install: - openssl aes-256-cbc -K $encrypted_9655a05d2431_key -iv $encrypted_9655a05d2431_iv -in id_rsa.enc -out ~/.ssh/id_rsa -d - chmod 600 ~/.ssh/id_rsa 同时，因为 travis 第一次登录远程服务器的时候会出现 SSH 主机验证，我们无法控制交互，所以要添加 addons 配置： 12addons: ssh_known_hosts: your_ip_addr:port 注意，如果你的服务器 ssh 端口是开在 22 的（强烈不推荐），上面的值可以只是 your_ip_addr。如果不是开在 22 端口，就要按照上面的格式自己填充。 这样配置完成后，travis 就可以免密登录自己的服务器了。 部署脚本既然已经可以免密登录服务器了，那么我们写一个部署脚本，在登录的时候自动执行即可。 1echo &quot;Auto Deploy Success&quot; &gt;&gt; a.log 记得要给脚本添加执行权限（x）。 执行部署脚本在 .travis.yml 中添加： 12after_success: - ssh your-username@your_ip_addr -p your_port &quot;./your_shell-script.sh&quot; 将其中的 your-username, your_id_addr, your_port, your_shell_script 替换成自己的即可。 自动部署项目到 Tomcat上面的设置完成后，我们已经可以让 travis 在测试完成后自动执行服务器上的脚本了，如果想自动部署到 Tomcat 我们只需要自己编写脚本即可。因为各自使用的 Tomcat 配置都有差别，就不再举例。 在项目中添加 badge点击 Travis 网站中 buid badge，选择 Markdown，将代码复制到项目 README 中即可看到 build:passing 的Badge。","tags":["java","ci"],"categories":["Technology"]},{"title":"编译原理之 Chomsky 文法的判断 —— Java 实现","path":"//posts/compiling-principle-chomsky/","content":"文法的定义和记号 $$ G &#x3D; (V_N, V_T, P, S) \\qquad (V_N \\cap V_T &#x3D; \\varnothing, V_N \\cup V_T &#x3D; V) $$ 是 N.Chomsky 在 1956 年描述形式语言时首先给出的。同时，Chomsky 还对产生式的形式给以不同的限制而定义了四类基本的文法，分别称之为 0 型文法，1 型文法，2 型文法和 3 型文法。 明确定义 0 型文法：对任一产生式 $\\alpha \\to \\beta$，都有 $\\alpha \\in V^+, \\quad \\beta \\in V^*$ 1 型文法：对任一产生式 $\\alpha \\to \\beta$，都有 $\\mid\\beta\\mid \\ge \\mid\\alpha\\mid, \\quad \\alpha,\\beta \\in V^+$，仅仅 $\\alpha \\to \\epsilon$ 除外 2 型文法：对任一产生式 $A \\to \\beta$，都有 $A \\in V_N, \\quad \\beta \\in V^+$ 3 型文法：任一产生式都形如 $A \\to Ba$ 或 $A \\to a$，其中 $A,B \\in V_N, \\quad a \\in V_T$，该文法称为右线性文法。类似可定义左线性文法。 判断思路0 型文法 字符串 $\\alpha$ 的范围是 $V^+$，是全符号集的一个正闭包，即符号集中所有符号的任意组合，且不包含 $\\epsilon$ 元素 字符串 $\\beta$ 的范围是 $V^*$，是全符号集的自反传递闭包，也即 $V^+ \\cup {\\epsilon}$ 要判断一个文法是否是 0 型文法，只需要判断左侧非空且不全为小写即可 任何 0 型语言都是递归可枚举的，故 0 型语言又称递归可枚举集 1 型文法 首先 1 型文法必须是 0 型文法 1 型文法除了 $\\alpha \\to \\epsilon$ 这个特例外，其他情况都满足 $\\beta$ 的长度大于 $\\alpha$ 的长度 1 型文法也叫上下文相关（敏感）文法 2 型文法 首先 2 型文法必须是 1 型文法 2 型文法左侧必须是一个非终结符 2 型文法也叫上下文无关文法 3 型文法 首先 3 型文法必须是 2 型文法 3 型文法必须满足以下两种形式之一 $A \\to aB$ 或 $A \\to a$ $A \\to Ba$ 或 $A \\to a$ 3 型文法也叫正规文法 代码实现保存产生式集可以使用 List 来保存所有产生式，用内部类来表示具体的产生式： 12345678910111213public class Chomsky &#123; private List&lt;Producer&gt; producers = new ArrayList&lt;&gt;(); private static final class Producer &#123; String left; String right; public Producer(String left, String right) &#123; this.left = left; this.right = right; &#125; &#125;&#125; 判断 0 型文法遍历产生式集，如果有一个产生式不符合条件，则直接退出。 123456789public boolean isZero() &#123; for (Producer producer : producers) &#123; if (producer.left.length() == 0 || producer.left.equals(producer.left.toLowerCase())) &#123; // 判断产生式的左部是否为空或者全部是小写，如果是则不是 0 型文法 return false; &#125; &#125; return true;&#125; 关于判断左部是否全为小写，使用 String.toLowerCase() 将其转换为小写后再与原产生式比较，相等则原产生式为小写。 判断 1 型文法12345678910111213public boolean isFirst() &#123; if (isZero()) &#123; for (Producer producer : producers) &#123; if (producer.right.length() != 0 &amp;&amp; producer.right.length() &lt; producer.left.length()) &#123; // 1 型文法必须右部长度大于左部，除了右部为ε的情况 return false; &#125; &#125; return true; &#125; else &#123; return false; &#125;&#125; 1 型文法必须先是 0 型文法。 1 型文法的判断跳过了右部为 $\\epsilon$ 的情况，即允许右部为 $\\epsilon$。 判断 2 型文法12345678910111213public boolean isSecond() &#123; if (isFirst()) &#123; for (Producer producer : producers) &#123; if (producer.left.length() != 1 || producer.left.matches(&quot;[a-z]&quot;)) &#123; // 2 型文法左部必须为 1，且左部为 1 时不能为非终结符 return false; &#125; &#125; return true; &#125; else &#123; return false; &#125;&#125; 2 型文法必须先是 1 型文法。 首先限制左部长度必须为 1，然后利用正则判断是否为小写，[a-z] 匹配一个小写字符。 判断 3 型文法12345678910111213141516171819202122public boolean isThird() &#123; if (isSecond()) &#123; int countLeft = 0, countRight = 0; for (Producer producer : producers) &#123; if (producer.right.matches(&quot;[A-Z]?[a-z]&quot;)) &#123; countLeft++; &#125; if (producer.right.matches(&quot;[a-z][A-Z]?&quot;)) &#123; countRight++; &#125; &#125; if (countLeft == producers.size()) &#123; System.out.println(&quot;此文法是 3 型文法，并且是左线性文法！&quot;); return true; &#125; if (countRight == producers.size()) &#123; System.out.println(&quot;此文法是 3 型文法，并且是右线性文法！&quot;); return true; &#125; &#125; return false;&#125; 3 型文法必须先是 2 型文法。 全部源代码Chomsky.java: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121import java.util.*;public class Chomsky &#123; private List&lt;Producer&gt; producers = new ArrayList&lt;&gt;(); public void add(Producer producer) &#123; producers.add(producer); &#125; public boolean isZero() &#123; for (Producer producer : producers) &#123; if (producer.left.length() == 0 || producer.left.equals(producer.left.toLowerCase())) &#123; // 判断产生式的左部是否为空或者全部是小写，如果是则不是 0 型文法 return false; &#125; &#125; return true; &#125; public boolean isFirst() &#123; if (isZero()) &#123; for (Producer producer : producers) &#123; if (producer.right.length() != 0 &amp;&amp; producer.right.length() &lt; producer.left.length()) &#123; // 1 型文法必须右部长度大于左部，除了右部为ε的情况 return false; &#125; &#125; return true; &#125; else &#123; return false; &#125; &#125; public boolean isSecond() &#123; if (isFirst()) &#123; for (Producer producer : producers) &#123; if (producer.left.length() != 1 || producer.left.matches(&quot;[a-z]&quot;)) &#123; // 2 型文法左部必须为 1，且左部为 1 时不能为非终结符 return false; &#125; &#125; return true; &#125; else &#123; return false; &#125; &#125; public boolean isThird() &#123; if (isSecond()) &#123; int countLeft = 0, countRight = 0; for (Producer producer : producers) &#123; if (producer.right.matches(&quot;[A-Z]?[a-z]&quot;)) &#123; countLeft++; &#125; if (producer.right.matches(&quot;[a-z][A-Z]?&quot;)) &#123; countRight++; &#125; &#125; if (countLeft == producers.size()) &#123; System.out.println(&quot;此文法是 3 型文法，并且是左线性文法！&quot;); return true; &#125; if (countRight == producers.size()) &#123; System.out.println(&quot;此文法是 3 型文法，并且是右线性文法！&quot;); return true; &#125; &#125; return false; &#125; /** * 判断文法的具体类型，从 3 到 0 逐步判断 */ public void test() &#123; if (!isThird()) &#123; if (isSecond()) &#123; System.out.println(&quot;此文法是 2 型文法&quot;); &#125; else if (isFirst()) &#123; System.out.println(&quot;此文法是 1 型文法&quot;); &#125; else if (isZero()) &#123; System.out.println(&quot;此文法是 0 型文法&quot;); &#125; else &#123; System.out.println(&quot;此文法不是 0 型文法！&quot;); &#125; &#125; &#125; private static final class Producer &#123; String left; String right; public Producer(String left, String right) &#123; this.left = left; this.right = right; &#125; &#125; public static void main(String[] args) &#123; int count; String[] input; Scanner scanner = new Scanner(System.in); Chomsky chomsky = new Chomsky(); System.out.println(&quot;请输入产生式的个数:&quot;); count = scanner.nextInt(); System.out.println(&quot;请依次输入产生式（示例：A-&gt;ab，一行一个）：&quot;); for (int i = 0; i &lt; count; i++) &#123; input = scanner.next().split(&quot;-&gt;&quot;); try &#123; chomsky.add(new Producer(input[0], input[1])); &#125; catch (ArrayIndexOutOfBoundsException e) &#123; System.out.println(&quot;输入非法，请重新运行程序！！！&quot;); System.exit(1); &#125; &#125; chomsky.test(); scanner.close(); &#125;&#125;","tags":["learn"],"categories":["Learn"]},{"title":"Spring Boot 项目打包并部署到 Tomcat、Tomcat 同时部署多应用","path":"//posts/spring-boot-project-package-and-deploy/","content":"Spring Boot 项目开发完毕后，需要部署到 tomcat 服务器下，鉴于经常忘记部署流程，特地写了一篇博客来记录。 打包为 war修改 packaging基于 Intellij IDEA 构建项目有一个好处是大多数东西它已经自动帮你设置好了，不需要太多修改的地方。 修改 pom.xml 中的打包格式： &lt;packaging&gt;jar&lt;/packaging&gt; –&gt; &lt;packaging&gt;war&lt;/packaging&gt; 插件与组件有的博客中提到了 build 组件和 tomcat 插件（pom.xml 中)，在 Intellij IDEA 生成的 pom 中并没有这些东西，所以可以直接跳过。 注册启动类修改 Application 类，继承 SpringBootServletInitializer 并重写 configure 方法，在方法中注册启动类： 1234567891011@SpringBootApplicationpublic class Application extends SpringBootServletInitializer &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(Application.class); &#125;&#125; 打包选择 Intellij IDEA 的 Build -&gt; Build Artifacts -&gt; ProjectName: war -&gt; Build，就会在项目根目录的 target 文件夹下生成：项目名+版本号.war。 Tomcat 同时部署多应用有时候受限于服务器资源，我们可能希望 Tomcat 同时运行多个应用。有两种解决方案：一种是单一 tomcat，通过配置文件同时服务多个应用；另一种是多个 tomcat，各个应用互不影响，但是比较麻烦。我们采用第一种方案。 Tomcat 默认的配置文件在 /path/to/tomcat/conf/server.xml 单一 tomcat 运行多应用的关键就是在 server.xml 中配置多个 Service。 默认的 Tomcat Service123456789101112&lt;Service name=&quot;Catalina&quot;&gt; &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName=&quot;UserDatabase&quot;/&gt; &lt;/Realm&gt; &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;java_dx_style_log&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt; &lt;/Engine&gt;&lt;/Service&gt; 要让 Tomcat 同时运行多应用，我们只需要新增 Service。 新增 Service新增 Service 有几点需要注意的： Service name 不能与原来的 Catalina 相同 HTTP port 和 AJP port 不能与原来的相同 Engine name 不能与原来的相同 Host 的 appBase 属性不能与原来的相同 以下是一个示例： 123456789101112&lt;Service name=&quot;newService&quot;&gt; &lt;Connector port=&quot;8081&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Connector port=&quot;8010&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Engine name=&quot;newService&quot; defaultHost=&quot;localhost&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName=&quot;UserDatabase&quot; /&gt; &lt;/Realm&gt; &lt;Host name=&quot;localhost&quot; appBase=&quot;newService&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;eros_dx_style_log&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt; &lt;/Engine&gt;&lt;/Service&gt; 修改完成后重启 Tomcat，部署新应用到上面配置文件指示的 /path/to/tomcat/newService 文件夹下即可。","tags":["deployment","java","spring boot"],"categories":["Java"]},{"title":"Spring Boot 集成 Shiro 权限管理与密码加盐加密存储","path":"//posts/spring-boot-shiro/","content":"在 Spring 中，流行的涉及权限管理的框架有两个：Spring Security 和 Apache Shiro。但是去了解一下 Spring Security 就知道，简单的权限管理根本用不到那么复杂的功能。在自己的项目中，我更倾向于使用简单明了的 Apache Shiro。 我们以最常见的用户、角色、权限关系做例子。一个用户有多个角色、一个角色有多个用户、一个角色有多个权限、一个权限有多个角色。即用户与角色、角色与权限是多对多关系。 引入 shiro-spring 包pom包依赖重要的是 shiro-spring 这个包。 12345678910111213141516171819202122&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- MariaDB --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mariadb.jdbc&lt;/groupId&gt; &lt;artifactId&gt;mariadb-java-client&lt;/artifactId&gt; &lt;version&gt;RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- shiro --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;RELEASE&lt;/version&gt;&lt;/dependency&gt; 配置文件123456789101112spring.datasource.driver-class-name=org.mariadb.jdbc.Driverspring.datasource.url=jdbc:mysql://localhost:3306/testspring.datasource.username=testspring.datasource.password=testspring.jpa.database=mysqlspring.jpa.show-sql=truespring.jpa.hibernate.ddl-auto=updatespring.thymeleaf.cache=falsespring.jackson.serialization.indent-output=true 实体类用户类12345678910111213141516171819202122232425262728293031323334package me.xlui.spring.entity;import javax.persistence.*;import java.io.Serializable;import java.util.List;@Entity@Table(name = &quot;shiro_user&quot;)public class User implements Serializable &#123; private static final long serialVersionUID = 1L; @Id @GeneratedValue private Long id; @Column(name = &quot;username&quot;, nullable = false, unique = true) private String username; private String password; private String salt; // 密码加盐 @ManyToMany(fetch = FetchType.EAGER) @JoinTable(name = &quot;shiro_user_role&quot;, joinColumns = &#123;@JoinColumn(name = &quot;user_id&quot;)&#125;, inverseJoinColumns = &#123;@JoinColumn(name = &quot;role_id&quot;)&#125;) private List&lt;Role&gt; roleList; @Override public String toString() &#123; return &quot;User[id = &quot; + id + &quot;, username = &quot; + username + &quot;, password = &quot; + password + &quot;, salt = &quot; + salt + &quot;]&quot;; &#125; public User() &#123; super(); &#125;// 省略 getter 和 setter&#125; 角色类123456789101112131415161718192021222324252627282930package me.xlui.spring.entity;import javax.persistence.*;import java.io.Serializable;import java.util.List;@Entity@Table(name = &quot;shiro_role&quot;)public class Role implements Serializable &#123; private static final long serialVersionUID = 1L; @Id @GeneratedValue private Long id; private String role; @ManyToMany @JoinTable(name = &quot;shiro_user_role&quot;, joinColumns = &#123;@JoinColumn(name = &quot;role_id&quot;)&#125;, inverseJoinColumns = &#123;@JoinColumn(name = &quot;user_id&quot;)&#125;) private List&lt;User&gt; userList; @ManyToMany @JoinTable(name = &quot;shiro_role_permission&quot;, joinColumns = &#123;@JoinColumn(name = &quot;role_id&quot;)&#125;, inverseJoinColumns = &#123;@JoinColumn(name = &quot;permission_id&quot;)&#125;) private List&lt;Permission&gt; permissionList; public Role() &#123; super(); &#125;// 省略 getter 和 setter&#125; 权限类1234567891011121314151617181920212223242526package me.xlui.spring.entity;import javax.persistence.*;import java.io.Serializable;import java.util.List;@Entity@Table(name = &quot;shiro_permission&quot;)public class Permission implements Serializable &#123; private static final long serialVersionUID = 1L; @Id @GeneratedValue private Long id; private String permission; @ManyToMany @JoinTable(name = &quot;shiro_role_permission&quot;, joinColumns = &#123;@JoinColumn(name = &quot;permission_id&quot;)&#125;, inverseJoinColumns = &#123;@JoinColumn(name = &quot;role_id&quot;)&#125;) private List&lt;Role&gt; roleList; public Permission() &#123; super(); &#125;// 省略 getter 和 setter&#125; 初始化数据库表123456789101112131415161718INSERT INTO shiro_user (id, password, salt, username) VALUES (1, &quot;dev&quot;, &quot;salt&quot;, &quot;admin&quot;);INSERT INTO shiro_role (id, role) VALUES (1, &quot;admin&quot;), (2, &quot;normal&quot;);INSERT INTO shiro_permission (id, permission) VALUES (1, &quot;user info&quot;), (2, &quot;user add&quot;), (3, &quot;user del&quot;);INSERT INTO shiro_user_role (user_id, role_id) VALUES (1, 1);INSERT INTO shiro_role_permission (permission_id, role_id) VALUES (1, 1), (2, 1); 查询接口UserRepository: 12345678package me.xlui.spring.repository;import me.xlui.spring.entity.User;import org.springframework.data.jpa.repository.JpaRepository;public interface UserRepository extends JpaRepository&lt;User, Long&gt; &#123; User findByUsername(String username);&#125; 其他省略。 Shiro 配置Apache Shiro 核心通过 Filter 实现，是基于 URL 规则来进行过滤和权限校验。我们通过注入类来进行 Shiro 的配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package me.xlui.spring.config;import org.apache.shiro.authc.credential.CredentialsMatcher;import org.apache.shiro.authc.credential.HashedCredentialsMatcher;import org.apache.shiro.mgt.SecurityManager;import org.apache.shiro.spring.security.interceptor.AuthorizationAttributeSourceAdvisor;import org.apache.shiro.spring.web.ShiroFilterFactoryBean;import org.apache.shiro.web.mgt.DefaultWebSecurityManager;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.LinkedHashMap;import java.util.Map;@Configurationpublic class ShiroConfiguration &#123; /** * 开启对注解 `@RequirePermission` 的支持 */ @Bean public AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor(SecurityManager securityManager) &#123; AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor = new AuthorizationAttributeSourceAdvisor(); authorizationAttributeSourceAdvisor.setSecurityManager(securityManager); return authorizationAttributeSourceAdvisor; &#125; /** * 自己实现的 Realm，Shiro 的认证最终都交给 Realm 进行执行了。我们需要自己实现一个 Realm，继承自 AuthrozingRealm */ @Bean public MyShiroRealm myShiroRealm() &#123; return new MyShiroRealm(); &#125; @Bean public SecurityManager securityManager() &#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(myShiroRealm()); return securityManager; &#125; @Bean public ShiroFilterFactoryBean shiroFilterFactoryBean(SecurityManager securityManager) &#123; ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean(); shiroFilterFactoryBean.setSecurityManager(securityManager); Map&lt;String, String&gt; filterChainDefinitionMap = new LinkedHashMap&lt;&gt;(); filterChainDefinitionMap.put(&quot;/logout&quot;, &quot;logout&quot;); filterChainDefinitionMap.put(&quot;/static&quot;, &quot;anon&quot;); // 将 /static 设置为 anon，避免登录后下载 favicon filterChainDefinitionMap.put(&quot;/**&quot;, &quot;authc&quot;); // authc 表示需要验证身份才能访问，anon 表示不需要 shiroFilterFactoryBean.setLoginUrl(&quot;/login&quot;); // 如果不设置，默认 Shiro 会寻找 classpath:/template/login.jsp 文件 shiroFilterFactoryBean.setSuccessUrl(&quot;/index&quot;); // 成功登陆后跳转 shiroFilterFactoryBean.setFilterChainDefinitionMap(filterChainDefinitionMap); return shiroFilterFactoryBean; &#125;&#125; 通过 ShiroFilterFactoryBean 来处理拦截资源文件的问题（单独的 ShiroFilterFactoryBean 配置会出错，因为 Shiro 还需要 SecurityManager）。 ShiroFilterFactory 中已经由 Shiro 官方实现的过滤器（只列举常用的）： Filter Name 作用 anon 匿名可访问 authc 需要认证 user 配置记住我或认证可访问 Shiro 认证和授权Shiro 的认证、授权最终都交给 Realm 来处理，同时在 Shiro 中，用户、角色和权限等信息也是在 Realm 中获取。我们要做的是自定义一个类，继承抽象基类 AuthorizingRealm： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package me.xlui.spring.config;import me.xlui.spring.entity.Permission;import me.xlui.spring.entity.Role;import me.xlui.spring.entity.User;import me.xlui.spring.repository.UserRepository;import me.xlui.spring.utils.LogUtil;import org.apache.shiro.authc.AuthenticationException;import org.apache.shiro.authc.AuthenticationInfo;import org.apache.shiro.authc.AuthenticationToken;import org.apache.shiro.authc.SimpleAuthenticationInfo;import org.apache.shiro.authc.credential.CredentialsMatcher;import org.apache.shiro.authc.credential.HashedCredentialsMatcher;import org.apache.shiro.authz.AuthorizationInfo;import org.apache.shiro.authz.SimpleAuthorizationInfo;import org.apache.shiro.realm.AuthorizingRealm;import org.apache.shiro.subject.PrincipalCollection;import org.apache.shiro.util.ByteSource;import org.springframework.beans.factory.annotation.Autowired;/** * Shiro 主要配置 */public class MyShiroRealm extends AuthorizingRealm &#123; @Autowired private UserRepository userRepository; /** * 负责授权 */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) &#123; LogUtil.getLogger().info(&quot;权限配置：MyShiroRealm.doGetAuthorizationInfo&quot;); SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); User user = (User) principalCollection.getPrimaryPrincipal(); LogUtil.getLogger().info(&quot;为用户 &quot; + user.getUsername() + &quot; 进行权限配置&quot;); for (Role role : user.getRoleList()) &#123; authorizationInfo.addRole(role.getRole()); for (Permission permission : role.getPermissionList()) &#123; authorizationInfo.addStringPermission(permission.getPermission()); &#125; &#125; return authorizationInfo; &#125; /** * 负责身份认证 */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException &#123; LogUtil.getLogger().info(&quot;开始身份认证&quot;); String username = (String) authenticationToken.getPrincipal(); LogUtil.getLogger().info(&quot;输入得到的用户名：&quot; + username); User user = userRepository.findByUsername(username); // 从数据库中查找 user if (user == null) &#123; return null; &#125; LogUtil.getLogger().info(&quot;用户信息： &quot; + user.toString()); SimpleAuthenticationInfo authenticationInfo = new SimpleAuthenticationInfo( user, user.getPassword(), // ByteSource.Util.bytes(user.getSalt()), 如果密码需要加盐验证，需要使用这个构造方法，后面会讲到。 getName() ); return authenticationInfo; &#125;&#125; 继承 AuthorizingRealm 类需要实现两个方法：doGetAuthorizationInfo() 和 doGetAuthenticationInfo()。doGetAuthorizationInfo() 负责权限管理，即为用户设置允许的权限，doGetAuthenticationInfo() 方法负责身份认证，即检验用户名密码的正确性。 123456SimpleAuthenticationInfo authenticationInfo = new SimpleAuthenticationInfo( user, user.getPassword(),// ByteSource.Util.bytes(user.getSalt()), 如果密码需要加盐验证，需要使用这个构造方法，后面会讲到。 getName()); 默认使用 CredentialsMatcher 来进行用户名密码确认，如果觉得默认的不好可以自己手动实现，下面讲密码加密存储会涉及到。注释的一行是密码加密时使用的盐，如果是明文密码去掉注释的一行即可。 接下来需要把自定义的 Realm 注入到 SecurityManager 中，代码在 ShiroConfiguration 类中已经实现： 1234567891011@Beanpublic MyShiroRealm myShiroRealm() &#123; return new MyShiroRealm();&#125;@Beanpublic SecurityManager securityManager() &#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(myShiroRealm()); return securityManager;&#125; 测试经过上面的操作 Shiro 的集成基本已经是完成了，下面进行测试： 控制器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package me.xlui.spring.web;import me.xlui.spring.entity.User;import me.xlui.spring.repository.UserRepository;import me.xlui.spring.utils.LogUtil;import org.apache.shiro.authc.IncorrectCredentialsException;import org.apache.shiro.authc.UnknownAccountException;import org.apache.shiro.authz.annotation.RequiresPermissions;import org.apache.shiro.crypto.hash.SimpleHash;import org.apache.shiro.util.ByteSource;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;import javax.servlet.http.HttpServletRequest;import java.util.Map;@Controllerpublic class HelloController &#123; @Autowired private UserRepository userRepository; @RequestMapping(&#123;&quot;/&quot;, &quot;/index&quot;&#125;) public String index() &#123; LogUtil.getLogger().info(&quot;HelloController.index&quot;); return &quot;index&quot;; &#125; @RequestMapping(&quot;/login&quot;) public String login(HttpServletRequest request, Map&lt;String, Object&gt; map) throws Exception &#123; LogUtil.getLogger().info(&quot;HelloController.login&quot;); String exception = (String) request.getAttribute(&quot;shiroLoginFailure&quot;); String msg = &quot;&quot;; if (exception != null) &#123; if (UnknownAccountException.class.getName().equals(exception)) &#123; LogUtil.getLogger().info(&quot;账户不存在！&quot;); msg = &quot;账户不存在&quot;; &#125; else if (IncorrectCredentialsException.class.getName().equals(exception)) &#123; // 实际应用的时候写 &quot;用户名或密码错误&quot; LogUtil.getLogger().info(&quot;密码不正确！&quot;); msg = &quot;密码错误&quot;; &#125; else &#123; LogUtil.getLogger().info(&quot;发生异常：&quot; + exception); msg = &quot;其他异常&quot;; &#125; &#125; map.put(&quot;msg&quot;, msg); return &quot;login&quot;; &#125;&#125; 模板index.html: 12345678910&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;/&gt; &lt;title&gt;Index&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;这是 Index 页！&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; login.html: 123456789101112131415&lt;!DOCTYPE html&gt;&lt;html xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;/&gt; &lt;title&gt;Login&lt;/title&gt;&lt;/head&gt;&lt;body&gt;错误信息：&lt;h4 style=&quot;color: red;&quot; th:text=&quot;$&#123;msg&#125;&quot;&gt;&lt;/h4&gt;&lt;form th:action=&quot;@&#123;/login&#125;&quot; method=&quot;post&quot;&gt; &lt;p&gt;用户名：&lt;input type=&quot;text&quot; name=&quot;username&quot; autofocus=&quot;autofocus&quot;/&gt;&lt;/p&gt; &lt;p&gt;密码：&lt;input type=&quot;password&quot; name=&quot;password&quot;/&gt;&lt;/p&gt; &lt;p&gt;&lt;input type=&quot;submit&quot; value=&quot;登录&quot;/&gt;&lt;/p&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 运行运行项目，访问 http://localhost:8080/。 密码加盐加密存储实际应用中我们往往不会直接明文存储密码，因为这样非常不安全。而单纯的使用 MD5、SHA 之类的算法加密密码会存在数据库中两个密码相同用户的 password 字段也相同的情况，这样也很容易被撞库攻击。一种更安全的方式是加盐加密。 加盐加密的思路是在使用 MD5、SHA 之类算法的时候在用户的密码字段加一个随机、唯一的字符串（盐），这样生成的加密密码串几乎不可能存在相同的。即使是两个相同的密码，因为盐的不同，生成的密码串也是万万不同的。 生成加盐密码串我采用的是访问特定 url 生成加盐密码串存储，实际应用的时候可以直接在用户注册或者修改密码的时候生成。 12345678910// HelloController@RequestMapping(&quot;/en&quot;)@ResponseBodypublic String encrypt() &#123; User user = userRepository.findByUsername(&quot;admin&quot;); user.setSalt(user.getUsername()); user.setPassword((new SimpleHash(&quot;MD5&quot;, user.getPassword(), ByteSource.Util.bytes(user.getSalt()), 1024)).toString()); userRepository.save(user); return &quot;succ&quot;;&#125; SimpleHash 是 Shiro 提供给我们的加密类，第一个参数是加密算法名，第二个参数是原密码，第三个参数是盐，因为在 Realm 中向 SimpleAuthenticationInfo 类传递参数时需要 ByteSource 类实例，所以我们在这里使用了相同的格式。实际上 SimpleHash 类对盐的具体类型没有要求，其形参的类型是 Object。第四个参数是加密的次数。 我们用自己的方式生成了加盐加密的密码串，接下来还需要告诉 Shiro 使用这种方式验证。 注入加密方式本来我们应该编写一个加密算法类，但是 Shiro 已经替我们实现了，HashedCredentialsMatcher，我们只需要注入使用即可。有两种使用方式： （1）重写 MyShiroRealm（自定义 Realm 类）的 setCredentialsMatcher 方法： 123456789101112public class MyShiroRealm extends AuthorizingRealm &#123;// ... @Override public void setCredentialsMatcher(CredentialsMatcher credentialsMatcher) &#123; // 重写 setCredentialsMatcher 方法为自定义的 Realm 设置 hash 验证方法 HashedCredentialsMatcher hashedCredentialsMatcher = new HashedCredentialsMatcher(); hashedCredentialsMatcher.setHashAlgorithmName(&quot;MD5&quot;); hashedCredentialsMatcher.setHashIterations(1024); super.setCredentialsMatcher(hashedCredentialsMatcher); &#125;&#125; （2）在 ShiroConfiguration 中注入： 12345678910111213141516171819@Configurationpublic class ShiroConfiguration &#123;// ... @Bean public HashedCredentialsMatcher hashedCredentialsMatcher()&#123; HashedCredentialsMatcher hashedCredentialsMatcher = new HashedCredentialsMatcher(); hashedCredentialsMatcher.setHashAlgorithmName(&quot;md5&quot;); hashedCredentialsMatcher.setHashIterations(1024); return hashedCredentialsMatcher; &#125; @Bean public MyShiroRealm myShiroRealm() &#123; MyShiroRealm myShiroRealm = new MyShiroRealm(); myShiroRealm.setCredentialsMatcher(hashedCredentialsMatcher()); return myShiroRealm; &#125;&#125; 两种方法无太大优劣，都可以成功告知 Shiro 使用这种方式进行加盐密码验证。 如果觉得默认的 HashedCredentialsMatcher 不好，可以自己动手实现一个，继承 CredentialsMatcher 接口，然后按照上面的方法集成即可。 验证运行程序，访问 http://localhost:8080/en，跳转到登录，登录后返回，对密码进行加盐存储。 查看数据库中用户表相应字段是否更新。 关闭浏览器，重新访问 http://localhost:8080 使用原用户名密码成功登录。 吐槽Spring Boot 和 Shiro 似乎存在一些问题。我一般开发的时候都在配置文件（application.properties）中这样设置： 1spring.jpa.hibernate.ddl-auto=create 然后再 classpath 也就是 src&#x2F;main&#x2F;resources 下新建 data.sql。这样 Spring Boot 在启动的时候就会删除所有相关表重建并且执行 data.sql 中的语句进行初始化。 但是在使用 Shiro 的情况下 data.sql 一直无法成功执行。Google 和 StackOverflow 都没有发现理想的回答[摊手]。 还有就是关于密码加盐存储这一点，百度到的博客基本就是抄来抄去，大部分只提了如何给密码加盐，基本没提到加盐存储之后 Shiro 如何验证。 源码源代码已经上传 GitHub：https://github.com/xlui/Spring-Boot-Examples/tree/master/spring-boot-shiro。如果对你有所帮助，不妨留个 star 再走。","tags":["java","spring boot","shiro"],"categories":["Java"]},{"title":"SpringBoot WebSocket 发送广播，Android 接收","path":"//posts/spring-boot-websocket-android-client/","content":"WebSocketWebSocket 为客户端、浏览器和服务端提供了双工异步通信的功能，即客户端（浏览器、Android）可以向服务器发送消息，服务器端也可以向客户端发送消息。 WebSocket 是通过一个 socket 来实现双工异步通信能力的。但是直接使用 WebSocket 协议开发程序会十分繁琐，因此我们使用它的子协议 STOMP，它是一个更高级别的协议。STOMP 协议使用一个基于帧的格式来定义消息，与 HTTP 的 request 和 response 类似（具有类似于 @RequestMpping 的注解 @MessageMapping）。 Spring Boot 的支持Spring Boot 对内嵌的 Tomcat、Jetty 和 Undertow 使用 WebSocket 提供了支持。 Spring Boot 为 WebSocket 提供的 starter pom 是 spring-boot-starter-websocket。 服务器端使用 Intellij IDEA + maven 搭建。spring-boot-starter 选择 Thymeleaf 和 WebSocket 创建拦截器拦截器可以在 WebSocket 握手前后进行一些预设置。 HandshakeInterceptor.java 123456789101112131415161718192021222324252627282930313233package me.xlui.im.config;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.http.server.ServerHttpRequest;import org.springframework.http.server.ServerHttpResponse;import org.springframework.web.socket.WebSocketHandler;import org.springframework.web.socket.server.support.HttpSessionHandshakeInterceptor;import java.util.Map;public class HandshakeInterceptor extends HttpSessionHandshakeInterceptor &#123; private static Logger logger = LoggerFactory.getLogger(&quot;xlui&quot;); /** * WebSocket 握手前 * &lt;p&gt; * 可以设置数据到 attributes 中，并在 WebSocketHandler 的 session 中获取 */ @Override public boolean beforeHandshake(ServerHttpRequest request, ServerHttpResponse response, WebSocketHandler wsHandler, Map&lt;String, Object&gt; attributes) throws Exception &#123; logger.info(&quot;HandshakeInterceptor: beforeHandshake&quot;); logger.info(&quot;Attributes: &quot; + attributes.toString()); return super.beforeHandshake(request, response, wsHandler, attributes); &#125; // WebSocket 握手后 @Override public void afterHandshake(ServerHttpRequest request, ServerHttpResponse response, WebSocketHandler wsHandler, Exception ex) &#123; logger.info(&quot;HandshakeInterceptor: afterHandshake&quot;); super.afterHandshake(request, response, wsHandler, ex); &#125;&#125; 创建配置类WebSocketConfig.java: 12345678910111213141516171819202122232425262728293031package me.xlui.im.config;import org.springframework.context.annotation.Configuration;import org.springframework.messaging.simp.config.MessageBrokerRegistry;import org.springframework.web.socket.config.annotation.AbstractWebSocketMessageBrokerConfigurer;import org.springframework.web.socket.config.annotation.EnableWebSocketMessageBroker;import org.springframework.web.socket.config.annotation.StompEndpointRegistry;@Configuration// 启用 Websocket 的消息代理@EnableWebSocketMessageBrokerpublic class WebSocketConfig extends AbstractWebSocketMessageBrokerConfigurer &#123;\t// 注册 STOMP 协议的节点（Endpoint），并映射为指定的 URL\t// 我们使用 STOMP，所以不需要再实现 WebSocketHandler。\t// 实现 WebSocketHandler 的目的是接收和处理消息，STOMP 已经为我们做了这些。\t@Override\tpublic void registerStompEndpoints(StompEndpointRegistry stompEndpointRegistry) &#123; // 注册 STOMP 协议的节点，并指定使用 SockJS 协议 stompEndpointRegistry.addEndpoint(&quot;/im&quot;).addInterceptors(new HandshakeInterceptor()).withSockJS();\t&#125;\t// 配置使用消息代理\t@Override\tpublic void configureMessageBroker(MessageBrokerRegistry registry) &#123; // 统一配置消息代理，消息代理即订阅点，客户端通过订阅消息代理点接受消息 registry.enableSimpleBroker(&quot;/b&quot;, &quot;/g&quot;, &quot;/user&quot;); // 配置点对点消息的前缀 registry.setUserDestinationPrefix(&quot;/user&quot;);\t&#125;&#125; 通过注解 @EnableWebSocketMessageBroker 开启使用 STOMP 协议来传输基于代理（message broker）的消息，这时控制器使用 @MessageMapping 就像使用 @RequestMapping 一样。 消息发送与接收类Message.java: 123456789101112package me.xlui.im.message;/** * 浏览器向服务端发送的消息应该用此类接受 */public class Message &#123; private String name; public String getName() &#123; return name; &#125;&#125; Response.java: 12345678910111213141516package me.xlui.im.message;/** * 服务器向客户端发送此类消息 */public class Response &#123; private String responseMessage; public Response(String responseMessage) &#123; this.responseMessage = responseMessage; &#125; public String getResponseMessage() &#123; return responseMessage; &#125;&#125; 控制器12345678910111213141516171819202122232425262728293031323334353637package me.xlui.im.web;import me.xlui.im.message.ChatMessage;import me.xlui.im.message.Message;import me.xlui.im.message.Response;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.messaging.handler.annotation.DestinationVariable;import org.springframework.messaging.handler.annotation.MessageMapping;import org.springframework.messaging.handler.annotation.SendTo;import org.springframework.messaging.simp.SimpMessagingTemplate;import org.springframework.stereotype.Controller;@Controllerpublic class WebSocketController &#123; @Autowired SimpMessagingTemplate simpMessagingTemplate; // 当客户端向服务器发送请求时，通过 `@MessageMapping` 映射 /broadcast 这个地址 @MessageMapping(&quot;/broadcast&quot;) // 当服务器有消息时，会对订阅了 @SendTo 中的路径的客户端发送消息 @SendTo(&quot;/b&quot;) public Response say(Message message) &#123; return new Response(&quot;Welcome, &quot; + message.getName() + &quot;!&quot;); &#125; @MessageMapping(&quot;/group/&#123;groupID&#125;&quot;) public void group(@DestinationVariable int groupID, Message message) &#123; Response response = new Response(&quot;Welcome to group &quot; + groupID + &quot;, &quot; + message.getName() + &quot;!&quot;); simpMessagingTemplate.convertAndSend(&quot;/g/&quot; + groupID, response); &#125; @MessageMapping(&quot;/chat&quot;) public void chat(ChatMessage chatMessage) &#123; Response response = new Response(&quot;Receive message from user &quot; + chatMessage.getFromUserID() + &quot;: &quot; + chatMessage.getMessage()); simpMessagingTemplate.convertAndSendToUser(String.valueOf(chatMessage.getUserID()), &quot;/msg&quot;, response); &#125;&#125; 浏览器演示页面静态资源放在 src/main/resources/static 下 广播 broadcast.html123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;!doctype html&gt;&lt;html xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html;charset=UTF-8&quot;/&gt; &lt;title&gt;Spring Boot WebSocket 广播式&lt;/title&gt;&lt;/head&gt;&lt;body onload=&quot;disconnect()&quot;&gt;&lt;noscript&gt; &lt;h2 style=&quot;color: #ff0000;&quot;&gt;貌似你的浏览器不支持 websocket&lt;/h2&gt;&lt;/noscript&gt;&lt;div&gt; &lt;button id=&quot;connect&quot; onclick=&quot;connect();&quot;&gt;连接&lt;/button&gt; &lt;button id=&quot;disconnect&quot; onclick=&quot;disconnect();&quot; disabled=&quot;disabled&quot;&gt;断开连接&lt;/button&gt;&lt;/div&gt;&lt;div id=&quot;conversationDiv&quot;&gt; &lt;label for=&quot;name&quot;&gt;输入你的名字：&lt;/label&gt; &lt;input type=&quot;text&quot; id=&quot;name&quot; placeholder=&quot;name&quot;/&gt; &lt;button id=&quot;sendName&quot; onclick=&quot;sendName();&quot;&gt;发送&lt;/button&gt; &lt;p id=&quot;response&quot;&gt;&lt;/p&gt;&lt;/div&gt;&lt;script th:src=&quot;@&#123;sockjs.min.js&#125;&quot;&gt;&lt;/script&gt;&lt;script th:src=&quot;@&#123;stomp.min.js&#125;&quot;&gt;&lt;/script&gt;&lt;script th:src=&quot;@&#123;jquery.js&#125;&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt; var stompClient = null; function setConnected(connected) &#123; conn = $(&#x27;#connect&#x27;); disconn = $(&#x27;#disconnect&#x27;); if (connected) &#123; conn.attr(&#x27;disabled&#x27;, &#x27;true&#x27;); disconn.removeAttr(&#x27;disabled&#x27;); &#125; else &#123; conn.removeAttr(&#x27;disabled&#x27;); disconn.attr(&#x27;disabled&#x27;, &#x27;true&#x27;); &#125; document.getElementById(&#x27;conversationDiv&#x27;).style.visibility = connected ? &#x27;visible&#x27; : &#x27;hidden&#x27;; $(&#x27;#response&#x27;).html(); &#125; function connect() &#123; var socket = new SockJS(&quot;/im&quot;); stompClient = Stomp.over(socket); stompClient.connect(&#123;&#125;, function (frame) &#123; setConnected(true); console.log(&#x27;Connected: &#x27; + frame); stompClient.subscribe(&#x27;/b&#x27;, function (response) &#123; showResponse(JSON.parse(response.body).response); &#125;); &#125;); &#125; function disconnect() &#123; if (stompClient != null) &#123; stompClient.disconnect(); &#125; setConnected(false); console.log(&#x27;Disconnected&#x27;); &#125; function sendName() &#123; var name = $(&#x27;#name&#x27;).val(); stompClient.send(&#x27;/broadcast&#x27;, &#123;&#125;, JSON.stringify(&#123;&#x27;name&#x27;: name&#125;)); &#125; function showResponse(message) &#123; var response = $(&#x27;#response&#x27;); response.html(response.text() + &#x27;\\r &#x27; + message); &#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 动态群组与点对点聊天的代码见 GitHub。 配置路径映射WebMvcConfig.java: 123456789101112131415package me.xlui.im.config;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.ViewControllerRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;@Configurationpublic class WebMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(&quot;/broadcast&quot;).setViewName(&quot;/broadcast&quot;); registry.addViewController(&quot;/group&quot;).setViewName(&quot;/group&quot;); registry.addViewController(&quot;/chat&quot;).setViewName(&quot;/chat&quot;); &#125;&#125; 浏览器测试运行程序，浏览器同时打开数个窗口，连接。 广播 动态群组 点对点 安卓客户端STOMP 协议在 Android 系统中没有默认实现，不过有开源项目已经实现了，所以我们只需要添加依赖直接使用就好。 build.gradle(project)12345678allprojects &#123; repositories &#123; google() jcenter() maven &#123; url &quot;https://jitpack.io&quot; &#125; // 添加 maven 仓库 &#125;&#125; build.gradle(app)123compile &#x27;com.squareup.okhttp3:okhttp:3.9.0&#x27;compile &#x27;org.java-websocket:Java-WebSocket:1.3.7&#x27;compile &#x27;com.github.NaikSoftware:StompProtocolAndroid:1.4.3&#x27; 我们使用的是 StompProtocolAndroid，它同时依赖于 WebSocket 的标准实现 Java-WebSocket。 不过 Java-WebSocket 实现的 WebSocket 类在我这里不太好使，所以我换了 okhttp 实现的 WebSocket 类。 网络权限在 AndroidManifest.xml 中添加网络权限： 1&lt;uses-permission android:name=&quot;android.permission.INTERNET&quot;/&gt; 布局 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;LinearLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; xmlns:tools=&quot;http://schemas.android.com/tools&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; android:gravity=&quot;center&quot; android:orientation=&quot;vertical&quot; tools:context=&quot;me.xlui.im.activities.BroadcastActivity&quot;&gt; &lt;!--tools:text=&quot;广播&quot; --&gt; &lt;LinearLayout android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:orientation=&quot;horizontal&quot;&gt; &lt;Button android:id=&quot;@+id/broadcast&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:layout_weight=&quot;1&quot; android:text=&quot;@string/broadcast&quot; /&gt; &lt;Button android:id=&quot;@+id/groups&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:layout_weight=&quot;1&quot; android:text=&quot;@string/groups&quot; /&gt; &lt;Button android:id=&quot;@+id/chat&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:layout_weight=&quot;1&quot; android:text=&quot;@string/chat&quot; /&gt; &lt;/LinearLayout&gt; &lt;LinearLayout android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:gravity=&quot;center_vertical|center&quot; android:orientation=&quot;horizontal&quot;&gt; &lt;TextView android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:padding=&quot;12dp&quot; android:text=&quot;@string/broadcast_prompt&quot; /&gt; &lt;EditText android:id=&quot;@+id/name&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:inputType=&quot;text&quot; android:padding=&quot;16dp&quot; /&gt; &lt;/LinearLayout&gt; &lt;Button android:id=&quot;@+id/send&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:text=&quot;@string/send&quot; /&gt; &lt;TextView android:id=&quot;@+id/show&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; /&gt;&lt;/LinearLayout&gt; 主程序广播 Activity 的代码，其他代码（动态群组、点对点）见 GitHub。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113package me.xlui.im.activities;import android.content.Intent;import android.support.v7.app.AppCompatActivity;import android.os.Bundle;import android.util.Log;import android.widget.Button;import android.widget.EditText;import android.widget.TextView;import android.widget.Toast;import org.json.JSONException;import org.json.JSONObject;import org.reactivestreams.Subscriber;import org.reactivestreams.Subscription;import me.xlui.im.R;import me.xlui.im.conf.Const;import me.xlui.im.util.StompUtils;import okhttp3.WebSocket;import ua.naiksoftware.stomp.Stomp;import ua.naiksoftware.stomp.client.StompClient;public class BroadcastActivity extends AppCompatActivity &#123; private Button broadcast; private Button groups; private Button chat; private EditText name; private Button send; private TextView result; private void init() &#123; broadcast = findViewById(R.id.broadcast); broadcast.setEnabled(false); groups = findViewById(R.id.groups); chat = findViewById(R.id.chat); name = findViewById(R.id.name); send = findViewById(R.id.send); result = findViewById(R.id.show); &#125; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_broadcast); this.init(); StompClient stompClient = Stomp.over(WebSocket.class, Const.address); // 连接服务器 stompClient.connect(); Toast.makeText(this, &quot;开始连接&quot;, Toast.LENGTH_SHORT).show(); StompUtils.connect(stompClient); // 订阅消息 stompClient.topic(Const.broadcastResponse).subscribe(stompMessage -&gt; &#123; JSONObject jsonObject = new JSONObject(stompMessage.getPayload()); Log.i(Const.TAG, &quot;Receive: &quot; + stompMessage.getPayload()); runOnUiThread(() -&gt; &#123; try &#123; result.append(jsonObject.getString(&quot;response&quot;) + &quot; &quot;); &#125; catch (JSONException e) &#123; e.printStackTrace(); &#125; &#125;); &#125;); send.setOnClickListener(v -&gt; &#123; JSONObject jsonObject = new JSONObject(); try &#123; jsonObject.put(&quot;name&quot;, name.getText()); &#125; catch (JSONException e) &#123; e.printStackTrace(); &#125; stompClient.send(Const.broadcast, jsonObject.toString()).subscribe(new Subscriber&lt;Void&gt;() &#123; @Override public void onSubscribe(Subscription s) &#123; Log.i(Const.TAG, &quot;onSubscribe: 订阅成功！&quot;); &#125; @Override public void onNext(Void aVoid) &#123; &#125; @Override public void onError(Throwable t) &#123; t.printStackTrace(); Log.e(Const.TAG, &quot;发生错误：&quot;, t); &#125; @Override public void onComplete() &#123; Log.i(Const.TAG, &quot;onComplete: Send Complete!&quot;); &#125; &#125;); &#125;); groups.setOnClickListener(v -&gt; &#123; Intent intent = new Intent(); intent.setClass(BroadcastActivity.this, GroupActivity.class); startActivity(intent); this.finish(); &#125;); chat.setOnClickListener(v -&gt; &#123; Intent intent = new Intent(); intent.setClass(BroadcastActivity.this, ChatActivity.class); startActivity(intent); this.finish(); &#125;); &#125;&#125; 测试广播 动态群组 点对点 源码源代码已经上传到 GitHub，https://github.com/xlui/WebSocketExample，欢迎 star。","tags":["java","spring boot","websocket","android"],"categories":["Java"]},{"title":"Nginx 提供文件下载服务","path":"//posts/nginx-provide-download/","content":"有时候我们可能需要提供一些配置文件或安装包的下载链接，这种场景使用 CDN 有些杀鸡用牛刀，通过 Eginx 配置可以简单快速的提供功能。 Nginx 配置： 12345678910111213server &#123; listen 80; server_name download.akise.app; root /path/to/download.akise.app; location / &#123; index index.html; &#125; location /app &#123; default_type application/octet-stream; &#125;&#125; 文件夹配置： 12mkdir /path/to/download.akise.app/apptouch /path/to/download.akise.app/app/t.apk 浏览器访问 http://download.akise.app/app/t.apk 即会自动开始下载。","tags":["nginx","linux"],"categories":["Nginx"]},{"title":"Nginx 自定义静态资源位置","path":"//posts/nginx-static-resources/","content":"nginx [Engine X] is an HTTP and reverse proxy server, a mail proxy server, and a generic TCP&#x2F;UDP proxy server, originally written by Igor Sysoev. 起因项目后端之前变更为了 Flask 框架 + RESTful API 模式，然后通过 Gunicorn + Supervisor + Nginx 部署在 CentOS 7 服务器上。最近客户端需要访问服务器提供的静态资源（图片），我在 Flask 中配置了静态资源后客户端却无法访问。 项目结构： 123456789├─app│ ├─api_dev│ ├─api_error│ ├─api_stable│ ├─static│ │ └─images│ └─templates├─migrations└─test 在 app/static/images 文件夹下有一个 test.png 测试图片。在 Win10 本地运行项目，访问 http://127.0.0.1:5000/static/images/test.png 可以正常看到测试图片，但是当部署到服务器后，无法正常访问图片。 排查原因在 Win10 和手机浏览器访问 https://域名.com/static/images/test.png 都显示 404 Not Found。 在云服务器使用命令： 1curl 127.0.0.1:5000/static/images/test.png 发现结果是乱码： 证明成功访问到了图片资源。 以上测试说明，服务器端代码没有问题。那么问题一定出在 Gunicorn + Supervisor + Nginx 其中的一环，其他两个组件不涉及 URL 路由，那就一定是 Nginx 配置的问题了。 Nginx 配置由于我是用的是 lnmp 一键安装包，所以 Nginx 配置是自动生成的，检查配置文件 /use/local/nginx/conf/vhost/域名.com.conf 发现并没有对静态资源做相应的配置。我们之前出错的页面显示的是 404 Not Found 说明 Nginx 并没有找到我们的静态文件。 因为使用了 vhost，所以配置文件中默认的 root 地址并不是我们项目的地址，我首先尝试修改 root 值为 /path/to/project/root/app 但是没有解决问题。 因为是 Flask 项目，使用 Nginx 做反向代理，所以我尝试这在 proxy_pass 中配置了静态资源的路径，依然不行。 解决问题通过 Google 发现，需要自己配置静态文件的路径。在参考了 StackOverflow 上部分配置文件的内容后终于成功了！ 1234location ^~ /static &#123; root /path/to/project/root/app/; expires 30d;&#125; 还记得我的目录树吗？不记得了可以往上翻。请记住，如果你这样写，root 的路径一定是 static 目录的上层目录。 总结出现问题，一步一步排查缩小可能出现问题的范围，发现问题原因，尝试手动解决，谷歌、StackOverflow、官方文档，解决问题。按照着这个步骤走下去，大部分 Linux 上的问题都可以成功解决的吧！","tags":["nginx","linux"],"categories":["Nginx"]},{"title":"Centos7 系统使用 Gunicorn、Supervisor、Nginx 部署使用了工厂模式的 Flask 项目","path":"//posts/python-flask-deploy/","content":"项目后端从原始 socket 模式切换到了 RESTful API，考虑到项目的复杂度不高，于是我决定采用 Flask 来实现，本文记录一下基于 Gunicorn、Supervisor 和 Nginx 的最终的部署过程。 我们使用一个简单的 Flask Demo 来跑通整个流程。 Flask项目结构： 123456789|-REST-Server |-app |-__init__.py |-api_0_1_0 |-__init__.py |-views.py |-config.py |-manage.py |-wsgi.py 考虑到版本向下兼容，同时为了测试方便，使用不同的目录区分不同的 API 版本。在 app/__init__.py 中的 create_app() 函数中注册所有受支持的 api 蓝本（依据不同的 api 版本，在注册的时候设置不同的前缀，本例设置的前缀是：/api/v0.1.0），这样就做到了同时支持新旧功能。 app 文件夹是项目主体manage.py 主要是本地测试使用config.py 是配置文件wsgi.py 是部署文件，其内容是： 12345from app import create_appapp = create_app()if __name__ == &#x27;__main__&#x27;: app.run() GunicornGunicorn (独角兽)是一个高效的 Python WSGI Server，通常用它来运行 WSGI 应用（由我们编写的符合 WSGI 标准的后端服务）或者 WSGI 框架(如 Django，Paster 等)，其地位相当于 Java 中的 Tomcat。 使用 pip 安装： 1pip install gunicorn 在项目 root 目录下（有 wsgi.py 的那个目录）运行： 1gunicorn -w 2 -b 127.0.0.1:5000 wsgi:app -w 后接工作线程数 -b 后接绑定地址，即本机访问地址 wsgi 即第一步中的部署文件 app 是部署文件中的全局变量 app 运行后，在本地用 curl localhost:5000/api/v0.1.0（该命令受你的配置影响。/api/v0.1.0是我注册蓝本时添加的前缀，如果你注册时并没有添加，请不要使用此链接）即可成功访问。 Supervisor利用 yum 可以直接安装 Supervisor，需要注意 Supervisor 是直接运行在系统中的，所以不要在虚拟环境中安装。 而且 Supervisor 也只支持 Python2。 1yum install supervisor 创建配置文件：/etc/supervisord.d/server.ini 123456789101112[program:server]directory=/项目目录command=/虚拟环境目录/bin/gunicorn -w 2 -b 127.0.0.1:5000 wsgi:appautostart=trueautorestart=trueuser=用户startsecs=3startretries=5redirect_stderr=truestdout_logfile_maxbytes=50MBstdout_logfile_backups=10stdout_logfile=/opt/server.log 修改 /etc/supervisord.conf 将配置文件包含进来： 12[include]files = supervisord.d/*.ini 在我写这篇文章的时候，通过 yum 安装的 Supervisor 的配置文件已经默认是上边的格式，所以你只需要在 /etc/supervisord.d/ 下创建你的 程序.ini 即可。 配置完成后启动： 1supervisord -c /etc/supervisord.conf Nginx关于正向代理和反向代理的概念只是不同位置请求网络资源的不同说法，你用笔记本上网浏览网页通过的一个代理就叫正向代理，如果互联网过来的一个请求访问一个 IDC 机房的一个内网 web 服务，这个服务由 nginx 转进来就叫做反向代理，nginx 一般用于反向代理和负载均衡，这个 IDC 机房的 web 服务也可以直接用公网IP访问，但是为了解决高并发负载均衡的问题引入了 nginx 反向代理这个概念。 一个服务器只能对外暴露一个 80 端口，而我们有多个服务同时在跑，因此我们就需要借助 Nginx 反向代理，复用 80 端口，由 Nginx 完成 [客户端 -&gt; 域名 -&gt; 服务器 -&gt; 具体服务] 中，服务器接收到请求后路由给特定服务的工作。 12345678910111213141516171819202122232425262728293031323334353637server &#123; listen 80 default_server; server_name _; #index index.html index.htm index.php; # 重要的是这部分 location / &#123; proxy_pass http://127.0.0.1:5000/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; &#125; location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 30d; &#125; location ~ .*\\.(js|css)?$ &#123; expires 12h; &#125; location ~ /.well-known &#123; allow all; &#125; location ~ /\\. &#123; deny all; &#125; access_log /home/wwwlogs/access.log;&#125; 用 nginx -t 检查配置无误后重启 nginx。 验证打开本地浏览器，访问 ip/api/v0.1.0（后面的 /api/v0.1.0 基于你自己的配置，如果你在注册蓝本时没有设置前缀，请不要添加），成功看到 Hello World。","tags":["python","flask","deployment"],"categories":["Python"]},{"title":"关于本站","path":"/about/index.html","content":"网站搭建 网站基于 Hexo 搭建，源代码托管在 GitHub，网站部署在 GitHub Pages 上并使用 Cloudflare 加速访问。 关于我 Java 略知一二，Python 略知一二、Golang 略知一二、JavaScript 略知一二、Vue 略知一二、数据库略知一二、分布式系统略知一二。 Email: &#x61;&#107;&#x69;&#x61;&#107;&#x69;&#115;&#101;&#64;&#111;&#117;&#116;&#x6c;&#x6f;&#111;&#x6b;&#x2e;&#99;&#x6f;&#109; GitHub: https://github.com/akiakise StackOverflow: https://stackoverflow.com/users/7944150/aki-akise"},{"title":"小伙伴们","path":"/friends/index.html","content":"如果友链失联了？友链如果长期失联，可能会被取消！届时 GitHub Issue 的标签也会更新，如果您的网站恢复了，请在申请友链时创建的 Issue 中评论告知。 如何交换友链 您的网站需要满足以下全部条件： 合法的、非营利性、无商业广告、无木马植入 有实质性原创内容的 HTTPS 站点，发布过至少 5 篇原创文章，内容题材不限 有独立域名，非免费域名 博客已运行至少半年，非刚搭建好 如果您已经满足条件，请按照如下步骤自助提交友链： 第一步: 新建 Issue新建 GitHub Issue 并按照新 Issue 模板填写并提交。第二步: 添加本站友链请将本站添加到您的友链中:123title: AA博客url: https://blog.akise.appavatar: https://blog.akise.app/img/website/avatar.jpg第三步: 等待站长操作我在收到新 Issue 后会结合上边的标准评估是否添加，如果添加会在 Issue 上新增 active 标签，标签新增完成后大约 3 分钟内友链就会生效。如果您需要更新自己的友链，请直接修改 Issue 内容，大约 3 分钟内生效，无需等待博客重新部署。"}]